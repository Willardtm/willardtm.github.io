<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>《统计学习方法》第四章 朴素贝叶斯法 | Klaus&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="这个方法在很多场景有用，但是自身对于朴素贝叶斯的熟悉度还不够，因此补课。后续会对《统计学习方法》一书进行系统的学习，博客按章更新。">
<meta name="keywords" content="数学学习">
<meta property="og:type" content="article">
<meta property="og:title" content="《统计学习方法》第四章 朴素贝叶斯法">
<meta property="og:url" content="http://yoursite.com/2019/10/14/《统计学习方法》第四章-朴素贝叶斯法/index.html">
<meta property="og:site_name" content="Klaus&#39;s Blog">
<meta property="og:description" content="这个方法在很多场景有用，但是自身对于朴素贝叶斯的熟悉度还不够，因此补课。后续会对《统计学习方法》一书进行系统的学习，博客按章更新。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzIe9U.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzInc4.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzI0HI.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzIrUP.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzIggg.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzI2vQ.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzIjbR.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzIzUx.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzoC8O.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzoP2D.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzoixe.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzoEqA.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzoQxg.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzo3rj.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzoJZn.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzoYaq.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/uzoaGT.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/KSuUDU.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/KSuB59.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/KSuo8I.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/KSuqr8.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/KSKSGn.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/10/14/KSKUzt.md.png">
<meta property="og:updated_time" content="2020-02-23T07:06:40.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="《统计学习方法》第四章 朴素贝叶斯法">
<meta name="twitter:description" content="这个方法在很多场景有用，但是自身对于朴素贝叶斯的熟悉度还不够，因此补课。后续会对《统计学习方法》一书进行系统的学习，博客按章更新。">
<meta name="twitter:image" content="https://s2.ax1x.com/2019/10/14/uzIe9U.png">
  
    <link rel="alternate" href="/atom.xml" title="Klaus&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Klaus&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">MIA SAN MIA</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-《统计学习方法》第四章-朴素贝叶斯法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/10/14/《统计学习方法》第四章-朴素贝叶斯法/" class="article-date">
  <time datetime="2019-10-14T03:50:45.000Z" itemprop="datePublished">2019-10-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/数学学习/">数学学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      《统计学习方法》第四章 朴素贝叶斯法
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  <!-- Table of Contents -->
		
		  <div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#先验概率"><span class="toc-number">1.</span> <span class="toc-text">先验概率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#后验概率"><span class="toc-number">2.</span> <span class="toc-text">后验概率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#条件概率"><span class="toc-number">3.</span> <span class="toc-text">条件概率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#朴素贝叶斯法"><span class="toc-number">4.</span> <span class="toc-text">朴素贝叶斯法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代码实现朴素贝叶斯算法"><span class="toc-number">5.</span> <span class="toc-text">代码实现朴素贝叶斯算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考来源"><span class="toc-number">6.</span> <span class="toc-text">参考来源</span></a></li></ol>
		  </div>
		
        <p>这个方法在很多场景有用，但是自身对于朴素贝叶斯的熟悉度还不够，因此补课。<br>后续会对《统计学习方法》一书进行系统的学习，博客按章更新。<br><a id="more"></a></p>
<h2 id="先验概率"><a href="#先验概率" class="headerlink" title="先验概率"></a>先验概率</h2><p>事件发生前的预判概率。可以是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出。一般都是单独事件概率，如P(x),P(y)。</p>
<h2 id="后验概率"><a href="#后验概率" class="headerlink" title="后验概率"></a>后验概率</h2><p>事件发生后求的反向条件概率；或者说，基于先验概率求得的反向条件概率。概率形式与条件概率相同。</p>
<h2 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h2><p>一个事件发生后另一个事件发生的概率。一般的形式为P(x|y)表示y发生的条件下x发生的概率。<br>条件概率公式：<br><img src="https://s2.ax1x.com/2019/10/14/uzIe9U.png" alt></p>
<p>其他公式补充：<br>(1)乘法公式：<br><img src="https://s2.ax1x.com/2019/10/14/uzInc4.png" alt><br>乘法公式可以推广到：<br><img src="https://s2.ax1x.com/2019/10/14/uzI0HI.png" alt></p>
<p>(2)全概率公式：<br>假设 E 的样本空间为S，A为E的时间，B1，B2，…，Bn为S的一个划分，且P(Bi)&gt;0(i=1.2，…，n)，则<br><img src="https://s2.ax1x.com/2019/10/14/uzIrUP.png" alt></p>
<p>(3)贝叶斯公式：<br><img src="https://s2.ax1x.com/2019/10/14/uzIggg.png" alt><br>上式可以理解为：<br><img src="https://s2.ax1x.com/2019/10/14/uzI2vQ.png" alt></p>
<p>其中A以及B为随机事件，且P(B)不为0。P(A|B)是指在事件B发生的情况下事件A发现的概率。<br>在贝叶斯定理中，每个名词都有约定俗称的名称：<br>P(A|B)是已知B发生后，A的条件概率。也由于得自B的取值而被称作A的后验概率。<br>P(A)是A的先验概率(或边缘概率)。之所以称为“先验”是因为它不用考虑任何B方面的因素。<br>P(B|A)是已知A发生后，B的条件概率。也由于得自A的取值而被称作B的后验概率。<br>P(B)是B的先验概率。</p>
<p>按这些术语，贝叶斯定理可表述为：<br>后验概率 = (似然性*先验概率)/标准化常量<br>也就是说，后验概率与先验概率和相似度的乘积成正比。<br>另外，比例 P(B|A)/P(B)也有时被称作标准似然度，贝叶斯定理可以表示为：<br>后验概率=标准似然度*先验概率</p>
<p>完整的贝叶斯公式：<br><img src="https://s2.ax1x.com/2019/10/14/uzIjbR.png" alt></p>
<p>(4)全概率公式和贝叶斯公式的应用<br><img src="https://s2.ax1x.com/2019/10/14/uzIzUx.png" alt></p>
<p>(5)联合概率分布公式<br><img src="https://s2.ax1x.com/2019/10/14/uzoC8O.png" alt></p>
<p>(6)条件概率分布<br><img src="https://s2.ax1x.com/2019/10/14/uzoP2D.png" alt></p>
<h2 id="朴素贝叶斯法"><a href="#朴素贝叶斯法" class="headerlink" title="朴素贝叶斯法"></a>朴素贝叶斯法</h2><p>朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入输出的联合概率分布；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。</p>
<p>先验概率分布：<br><img src="https://s2.ax1x.com/2019/10/14/uzoixe.png" alt></p>
<p>条件概率分布：<br><img src="https://s2.ax1x.com/2019/10/14/uzoEqA.png" alt></p>
<p>朴素贝叶斯法对条件概率分布作了独立性的假设：<br><img src="https://s2.ax1x.com/2019/10/14/uzoQxg.png" alt><br>朴素贝叶斯法分类时，对给定的输入x，通过学习到得模型计算后验概率分布P(Y=ck|X=x)，将后验概率最大的类作为 x 的类输出。<br><img src="https://s2.ax1x.com/2019/10/14/uzo3rj.png" alt><br>将独立性假设的式子带入后验概率，可以得到：<br><img src="https://s2.ax1x.com/2019/10/14/uzoJZn.png" alt><br>其中 ck 可以理解为类别，j 可以理解为特征个数。</p>
<p>因此，朴素贝叶斯分类器可以表示为：<br><img src="https://s2.ax1x.com/2019/10/14/uzoYaq.png" alt></p>
<p>在朴素贝叶斯分类器中，分母对所有ck都是相同的，所以，<br><img src="https://s2.ax1x.com/2019/10/14/uzoaGT.png" alt></p>
<p>在查资料的过程中我看到了这样一篇文章<a href="https://www.jianshu.com/p/160e0489e586" target="_blank" rel="noopener">通俗易懂理解朴素贝叶斯</a>我觉得文章写得很好，在这里分享出来。</p>
<h2 id="代码实现朴素贝叶斯算法"><a href="#代码实现朴素贝叶斯算法" class="headerlink" title="代码实现朴素贝叶斯算法"></a>代码实现朴素贝叶斯算法</h2><p>举个例子，一个分类问题也许有 k 个分类标签，y1,y2,…,yk 还有 n 个输入变量，X1,X2,…,Xn。我们可以通过一个例子或一系列给定的列值来计算一个条件概率：<br><img src="https://s2.ax1x.com/2019/10/14/KSuUDU.png" alt><br>条件概率可以用来计算问题中每个类标签的概率然后返回概率最高的标签作为最相似的分类结果。<br>我们可以把分类通过贝叶斯理论看作是一个条件分类问题：<br><img src="https://s2.ax1x.com/2019/10/14/KSuB59.png" alt><br>其中，先验概率 P(yi) 容易从数据集中进行估计得到，除非拥有足够大的数据集，否则 P(x1,x2,…,xn|yi) 的结果则很难获取。至此，直接的贝叶斯理论就变得棘手，尤其是当特征数不断增加时。<br>贝叶斯定理假设每个输入变量都依赖于所有其他变量，这就是计算复杂的原因。假设所有的变量彼此独立，首先将分母计算P(x1,x2,…,xn)移除，因为它是用于计算给定实例的每个类别的条件概率的常数，并且具有将结果归一化的效果。<br><img src="https://s2.ax1x.com/2019/10/14/KSuo8I.png" alt><br>接下来，将给定类标签的所有变量的条件概率转换为给定类标签的每个变量值的独立条件概率。再将这些独立条件变量相乘：<br><img src="https://s2.ax1x.com/2019/10/14/KSuqr8.png" alt><br>可以通过上式来计算每一个类别标签，概率最大的则作为给定序列的分类结果，这样简化的结果也就是贝叶斯分类。</p>
<p>给定类标签的特征值的条件概率也可以从数据中估计出来。具体来说，就是属于给定类的那些数据示例，以及每个变量的一个数据分布。这意味着如果有K个类和n个变量，那么必须创建和维护K * n个不同的概率分布。</p>
<p>下面使用Python完成一个朴素贝叶斯分类的例子，Python版本：3.6，IDE：Pycharm。<br>使用skit-learn这个库的make_blobs功能成了100个带有两个数值输入变量的样例，每个变量都指定了两个类中的一个。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line">X,y=make_blobs(n_samples=<span class="number">100</span>,centers=<span class="number">2</span>,n_features=<span class="number">2</span>,random_state=<span class="number">1</span>)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">make_blobs 参数说明</span></span><br><span class="line"><span class="string">n_samples: 生成的样例数</span></span><br><span class="line"><span class="string">n_features: 每个样本的特征数</span></span><br><span class="line"><span class="string">centers: 类别数</span></span><br><span class="line"><span class="string">random_state: 随机数种子</span></span><br><span class="line"><span class="string">注:random_state参数设置为1，以确保每次运行代码时都生成相同的随机观察样本。</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">print(X.shape,y.shape)</span><br><span class="line">print(X[:<span class="number">5</span>])</span><br><span class="line">print(y[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure></p>
<p>运行结果如下：<br><img src="https://s2.ax1x.com/2019/10/14/KSKSGn.png" alt></p>
<p>对模型使用高斯概率分布。这个可以通过使用SciPy这个库来实现norm，首先，可以指定分布参数（比如均值和标准偏差）来构造分布，然后可以使用norm.pdf()函数为特定值采样概率密度函数。<br>可以使用numpy函数中的mean()和std()从数据集中估计分布参数。<br>下面的fit_distribution()函数为一个变量获取数据样本，并拟合数据分布。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为一个单变量的数据样本拟合一个概率分布</span></span><br><span class="line">def fit_distribution(data):</span><br><span class="line">    # 估计参数</span><br><span class="line">    <span class="attribute">mu</span>=np.mean(data)</span><br><span class="line">    <span class="attribute">sigma</span>=np.std(data)</span><br><span class="line">    <span class="builtin-name">print</span>(mu,sigma)</span><br><span class="line">    # 拟合分布</span><br><span class="line">    <span class="attribute">dist</span>=norm(mu,sigma)</span><br><span class="line">    return dist</span><br></pre></td></tr></table></figure></p>
<p>我们对每个输入变量的条件概率感兴趣，这就意味着我们需要为每个输入变量分配一个分布，为每个类标签分配一组分布，也就是总共需要四组分布。</p>
<p>将数据分为每个类标签的样本组。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为数据分类</span></span><br><span class="line"><span class="attribute">Xy0</span>=X[<span class="attribute">y</span>==0]</span><br><span class="line"><span class="attribute">Xy1</span>=X[<span class="attribute">y</span>==1]</span><br><span class="line"><span class="builtin-name">print</span>(Xy0.shape,Xy1.shape)</span><br></pre></td></tr></table></figure></p>
<p>然后我们可以利用这些组来计算属于每个组的数据样本的先验概率。</p>
<p>假设我们在两个类的每一个中创建了相同数量的样例，这将准确地达到50%。尽管如此，为了完整性，我们仍然需要计算这些先验概率。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算先验概率</span></span><br><span class="line"><span class="attribute">priory0</span>=len(Xy0)/len(X)</span><br><span class="line"><span class="attribute">priory1</span>=len(Xy1)/len(X)</span><br><span class="line"><span class="builtin-name">print</span>(priory0,priory1)</span><br></pre></td></tr></table></figure>
<p>最后，使用 fit_distribution() 函数，我们定义来为每个变量和标签准备得概率分布。<br><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建y=0的概率分布</span></span><br><span class="line"><span class="attr">X1y0</span>=fit_distribution(Xy0[:,<span class="number">0</span>])</span><br><span class="line"><span class="attr">X2y0</span>=fit_distribution(Xy0[:,<span class="number">1</span>])</span><br><span class="line"><span class="comment"># 创建y=1的概率分布</span></span><br><span class="line"><span class="attr">X1y1</span>=fit_distribution(Xy0[:,<span class="number">0</span>])</span><br><span class="line"><span class="attr">X2y1</span>=fit_distribution(Xy0[:,<span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<p>将上述代码整合到一起<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">X,y=make_blobs(n_samples=<span class="number">100</span>,centers=<span class="number">2</span>,n_features=<span class="number">2</span>,random_state=<span class="number">1</span>)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">make_blobs 参数说明</span></span><br><span class="line"><span class="string">n_samples: 生成的样例数</span></span><br><span class="line"><span class="string">n_features: 每个样本的特征数</span></span><br><span class="line"><span class="string">centers: 类别数</span></span><br><span class="line"><span class="string">random_state: 随机数种子</span></span><br><span class="line"><span class="string">注:random_state参数设置为1，以确保每次运行代码时都生成相同的随机观察样本。</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">print(X.shape,y.shape)</span><br><span class="line">print(X[:<span class="number">5</span>])</span><br><span class="line">print(y[:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为一个单变量的数据样本拟合一个概率分布</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit_distribution</span><span class="params">(data)</span>:</span></span><br><span class="line">    <span class="comment"># 估计参数</span></span><br><span class="line">    mu=np.mean(data)</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    np.mean(a,axis=,dtype=,keepdims=) 求平均值</span></span><br><span class="line"><span class="string">    axis:0表示纵轴，axis=1表示横轴</span></span><br><span class="line"><span class="string">    keepdims:表示是否保持维度不变</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    sigma=np.std(data)</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    np.std 计算矩阵标准差，axis等参数同上</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    print(mu,sigma)</span><br><span class="line">    <span class="comment"># 拟合分布</span></span><br><span class="line">    dist=norm(mu,sigma)</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    scipy.stats.norm函数 可以实现正态分布</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">return</span> dist</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为数据分类</span></span><br><span class="line">Xy0=X[y==<span class="number">0</span>]</span><br><span class="line">Xy1=X[y==<span class="number">1</span>]</span><br><span class="line">print(Xy0.shape,Xy1.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算先验概率</span></span><br><span class="line">priory0=len(Xy0)/len(X)</span><br><span class="line">priory1=len(Xy1)/len(X)</span><br><span class="line">print(priory0,priory1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建y=0的概率分布</span></span><br><span class="line">X1y0=fit_distribution(Xy0[:,<span class="number">0</span>])</span><br><span class="line">X2y0=fit_distribution(Xy0[:,<span class="number">1</span>])</span><br><span class="line"><span class="comment"># 创建y=1的概率分布</span></span><br><span class="line">X1y1=fit_distribution(Xy0[:,<span class="number">0</span>])</span><br><span class="line">X2y1=fit_distribution(Xy0[:,<span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<p>运行之后可以得到：<br><img src="https://s2.ax1x.com/2019/10/14/KSKUzt.md.png" alt></p>
<p>下面，我们要使用已经准备好的概率模型来做预测。<br>每个类标签的独立条件概率可以使用类的先验(50%)和每个变量的值的条件概率来计算。在给定每个变量的先验和条件概率分布的情况下，下面的概率函数对一个输入示例（两个值的数组）执行此计算。由于数量未归一化，返回的值是分数而不是概率。<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算独立条件概率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">probability</span><span class="params">(X,prior,dist1,dist2)</span></span><span class="symbol">:</span></span><br><span class="line">    <span class="keyword">return</span> prior*dist1.pdf(X[<span class="number">0</span>])*dist2.pdf(X[<span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<p>可以通过这个函数计算属于每个类的样例的概率。</p>
<p>首先，可以选择一个示例进行分类，使用数据集中的第一个样例。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对一个样例进行分类</span></span><br><span class="line">Xsample,<span class="attribute">ysample</span>=X[0],y[0]</span><br></pre></td></tr></table></figure></p>
<p>然后，计算属于第一类的样例的得分，再计算属于第二类样例的得分，输出结果。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">py0</span>=probability(Xsample,priory0,distX1y0,distX2y0)</span><br><span class="line"><span class="attribute">py1</span>=probability(Xsample,priory1,distX1y1,distX2y1)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'P(y=0 | %s) = %.3f'</span> % (Xsample, py0<span class="number">*100</span>))</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'P(y=1 | %s) = %.3f'</span> % (Xsample, py1<span class="number">*100</span>))</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'Truth:y=%d'</span>%ysample)</span><br></pre></td></tr></table></figure></p>
<p>完整版的朴素贝叶斯分布代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为一个单变量的数据样本拟合一个概率分布</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit_distribution</span><span class="params">(data)</span>:</span></span><br><span class="line">    <span class="comment"># 估计参数</span></span><br><span class="line">    mu=np.mean(data)</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    np.mean(a,axis=,dtype=,keepdims=) 求平均值</span></span><br><span class="line"><span class="string">    axis:0表示纵轴，axis=1表示横轴</span></span><br><span class="line"><span class="string">    keepdims:表示是否保持维度不变</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    sigma=np.std(data)</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    np.std 计算矩阵标准差，axis等参数同上</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#print(mu,sigma)</span></span><br><span class="line">    <span class="comment"># 拟合分布</span></span><br><span class="line">    dist=norm(mu,sigma)</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    scipy.stats.norm函数 可以实现正态分布</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">return</span> dist</span><br><span class="line"></span><br><span class="line">X,y=make_blobs(n_samples=<span class="number">100</span>,centers=<span class="number">2</span>,n_features=<span class="number">2</span>,random_state=<span class="number">1</span>)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">make_blobs 参数说明</span></span><br><span class="line"><span class="string">n_samples: 生成的样例数</span></span><br><span class="line"><span class="string">n_features: 每个样本的特征数</span></span><br><span class="line"><span class="string">centers: 类别数</span></span><br><span class="line"><span class="string">random_state: 随机数种子</span></span><br><span class="line"><span class="string">注:random_state参数设置为1，以确保每次运行代码时都生成相同的随机观察样本。</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># print(X.shape,y.shape)</span></span><br><span class="line"><span class="comment"># print(X[:5])</span></span><br><span class="line"><span class="comment"># print(y[:5])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为数据分类</span></span><br><span class="line">Xy0=X[y==<span class="number">0</span>]</span><br><span class="line">Xy1=X[y==<span class="number">1</span>]</span><br><span class="line"><span class="comment">#print(Xy0.shape,Xy1.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算先验概率</span></span><br><span class="line">priory0=len(Xy0)/len(X)</span><br><span class="line">priory1=len(Xy1)/len(X)</span><br><span class="line"><span class="comment">#print(priory0,priory1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建y=0的概率分布</span></span><br><span class="line">distX1y0=fit_distribution(Xy0[:,<span class="number">0</span>])</span><br><span class="line">distX2y0=fit_distribution(Xy0[:,<span class="number">1</span>])</span><br><span class="line"><span class="comment"># 创建y=1的概率分布</span></span><br><span class="line">distX1y1=fit_distribution(Xy0[:,<span class="number">0</span>])</span><br><span class="line">distX2y1=fit_distribution(Xy0[:,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算独立条件概率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">probability</span><span class="params">(X,prior,dist1,dist2)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> prior*dist1.pdf(X[<span class="number">0</span>])*dist2.pdf(X[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对一个样例进行分类</span></span><br><span class="line">Xsample,ysample=X[<span class="number">0</span>],y[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">py0=probability(Xsample,priory0,distX1y0,distX2y0)</span><br><span class="line">py1=probability(Xsample,priory1,distX1y1,distX2y1)</span><br><span class="line">print(<span class="string">'P(y=0 | %s) = %.3f'</span> % (Xsample, py0*<span class="number">100</span>))</span><br><span class="line">print(<span class="string">'P(y=1 | %s) = %.3f'</span> % (Xsample, py1*<span class="number">100</span>))</span><br><span class="line">print(<span class="string">'Truth:y=%d'</span>%ysample)</span><br></pre></td></tr></table></figure></p>
<h2 id="参考来源"><a href="#参考来源" class="headerlink" title="参考来源"></a>参考来源</h2><p>[1]<a href="https://blog.csdn.net/yangang908/article/details/62215209" target="_blank" rel="noopener">https://blog.csdn.net/yangang908/article/details/62215209</a><br>[2]<a href="https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86</a><br>[3]李航《统计学习方法》第二版<br>[4]概率论与数理统计(课本)<br>[5]<a href="https://zhuanlan.zhihu.com/p/22467549" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/22467549</a><br>[6][代码实现部分参考]<a href="https://machinelearningmastery.com/classification-as-conditional-probability-and-the-naive-bayes-algorithm/" target="_blank" rel="noopener">https://machinelearningmastery.com/classification-as-conditional-probability-and-the-naive-bayes-algorithm/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/10/14/《统计学习方法》第四章-朴素贝叶斯法/" data-id="ckymbgwr200470gukynyhftk8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/数学学习/">数学学习</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/10/18/Skip-Gram模型与CBOW模型代码实现/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Skip-Gram模型与CBOW模型代码实现
        
      </div>
    </a>
  
  
    <a href="/2019/10/11/cs224n-2019-Lecture-7-梯度消失和有趣的RNN/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs224n(2019)-Lecture 7 梯度消失和有趣的RNN</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
    <h3 class="widget-title">联系方式</h3>
    <div class="widget">
	  <li><a>klausvon@163.com</a></li>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">目录</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CTF/">CTF</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/HTML/">HTML</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP-知识图谱/">NLP,知识图谱</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/VQA/">VQA</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/XSS漏洞学习/">XSS漏洞学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/代码审计/">代码审计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/开发/">开发</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学学习/">数学学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/漏洞学习/">漏洞学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境配置/">环境配置</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/神经网络/">神经网络</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CTF-Web/">CTF_Web</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HTML/">HTML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JavaScript/">JavaScript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ML/">ML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Model-Compression/">Model Compression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PHP/">PHP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQL-injection/">SQL_injection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VQA/">VQA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/XXE/">XXE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/凸包算法/">凸包算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/开发/">开发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数学学习/">数学学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据挖掘/">数据挖掘</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/环境配置/">环境配置</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/知识图谱/">知识图谱</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/神经网络/">神经网络</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithm/" style="font-size: 15px;">Algorithm</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/CTF-Web/" style="font-size: 18.33px;">CTF_Web</a> <a href="/tags/HTML/" style="font-size: 10px;">HTML</a> <a href="/tags/JavaScript/" style="font-size: 10px;">JavaScript</a> <a href="/tags/ML/" style="font-size: 11.67px;">ML</a> <a href="/tags/Model-Compression/" style="font-size: 10px;">Model Compression</a> <a href="/tags/NLP/" style="font-size: 20px;">NLP</a> <a href="/tags/PHP/" style="font-size: 10px;">PHP</a> <a href="/tags/Python/" style="font-size: 11.67px;">Python</a> <a href="/tags/SQL-injection/" style="font-size: 13.33px;">SQL_injection</a> <a href="/tags/VQA/" style="font-size: 10px;">VQA</a> <a href="/tags/XXE/" style="font-size: 10px;">XXE</a> <a href="/tags/凸包算法/" style="font-size: 10px;">凸包算法</a> <a href="/tags/大数据/" style="font-size: 10px;">大数据</a> <a href="/tags/开发/" style="font-size: 18.33px;">开发</a> <a href="/tags/数学学习/" style="font-size: 11.67px;">数学学习</a> <a href="/tags/数据挖掘/" style="font-size: 11.67px;">数据挖掘</a> <a href="/tags/环境配置/" style="font-size: 10px;">环境配置</a> <a href="/tags/知识图谱/" style="font-size: 16.67px;">知识图谱</a> <a href="/tags/神经网络/" style="font-size: 15px;">神经网络</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/01/12/单调栈的奇妙冒险/">单调栈的奇妙冒险</a>
          </li>
        
          <li>
            <a href="/2021/06/03/Basic-Understanding-of-Optimization/">Basic Understanding of Optimization</a>
          </li>
        
          <li>
            <a href="/2021/06/02/Why-Deep-Structure/">Why Deep Structure</a>
          </li>
        
          <li>
            <a href="/2021/05/23/Model-Compression-基本概念/">What is Model Compression</a>
          </li>
        
          <li>
            <a href="/2020/05/21/CSS在开发中的基本操作小结/">CSS在开发中的基本操作小结</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    <div class="widget-wrap">
    <h3 class="widget-title">友情链接</h3>
    <div class="widget">
	 <a class="theme-link"  href="https://mteacher.top/"> martini's blog </a><span>&nbsp;&nbsp;</span>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 Klaus<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>