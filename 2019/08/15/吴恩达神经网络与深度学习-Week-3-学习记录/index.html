<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>吴恩达神经网络与深度学习 Week-3 学习记录 | Klaus&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="开始浅层神经网络的学习。">
<meta name="keywords" content="神经网络">
<meta property="og:type" content="article">
<meta property="og:title" content="吴恩达神经网络与深度学习 Week-3 学习记录">
<meta property="og:url" content="http://yoursite.com/2019/08/15/吴恩达神经网络与深度学习-Week-3-学习记录/index.html">
<meta property="og:site_name" content="Klaus&#39;s Blog">
<meta property="og:description" content="开始浅层神经网络的学习。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/15/mAZDCF.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/15/mAZsgJ.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/15/mAZWE6.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/15/mAZogH.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVOqne.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVOL0H.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXS9P.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVX9c8.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXFBQ.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXk7j.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXucT.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXKjU.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXlB4.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVX1HJ.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVX8E9.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXGNR.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXJ41.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXBHH.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVX2gf.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXfKS.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXhDg.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXIEj.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXHCq.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/08/16/mVXjrF.png">
<meta property="og:updated_time" content="2019-08-15T21:39:14.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="吴恩达神经网络与深度学习 Week-3 学习记录">
<meta name="twitter:description" content="开始浅层神经网络的学习。">
<meta name="twitter:image" content="https://s2.ax1x.com/2019/08/15/mAZDCF.png">
  
    <link rel="alternate" href="/atom.xml" title="Klaus&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Klaus&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">MIA SAN MIA</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-吴恩达神经网络与深度学习-Week-3-学习记录" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/08/15/吴恩达神经网络与深度学习-Week-3-学习记录/" class="article-date">
  <time datetime="2019-08-14T20:26:22.000Z" itemprop="datePublished">2019-08-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/神经网络/">神经网络</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      吴恩达神经网络与深度学习 Week-3 学习记录
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  <!-- Table of Contents -->
		
		  <div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是神经网络"><span class="toc-number">1.</span> <span class="toc-text">什么是神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络表示"><span class="toc-number">2.</span> <span class="toc-text">神经网络表示</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#计算神经网络的输出"><span class="toc-number">3.</span> <span class="toc-text">计算神经网络的输出</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多个例子中的向量化"><span class="toc-number">4.</span> <span class="toc-text">多个例子中的向量化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#向量化实现的解释"><span class="toc-number">5.</span> <span class="toc-text">向量化实现的解释</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#激活函数"><span class="toc-number">6.</span> <span class="toc-text">激活函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#为什么需要非线性激活函数"><span class="toc-number">7.</span> <span class="toc-text">为什么需要非线性激活函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#激活函数的导数"><span class="toc-number">8.</span> <span class="toc-text">激活函数的导数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络的梯度下降"><span class="toc-number">9.</span> <span class="toc-text">神经网络的梯度下降</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#随机初始化"><span class="toc-number">10.</span> <span class="toc-text">随机初始化</span></a></li></ol>
		  </div>
		
        <p>开始浅层神经网络的学习。</p>
<a id="more"></a>
<h2 id="什么是神经网络"><a href="#什么是神经网络" class="headerlink" title="什么是神经网络"></a>什么是神经网络</h2><p>可以把很多sigmoid函数堆叠起来构成一个神经网络。在下图所示神经网络中的这堆节点计算对应着Logistic Regression中的计算过程。<br><img src="https://s2.ax1x.com/2019/08/15/mAZDCF.png" alt></p>
<p>在下面的描述中会使用到以下这些符号：<br>x:表示输入特征。<br>参数W和b的上标(比如 W[1])表示神经网络中节点相关的量，比如层数，[2]则表示是神经网络的另一层。<br>同时，(1)，也就是圆括号，是用来表示训练样本的，x(1)表示第一个训练样本。</p>
<p>在逻辑回归中只用计算一次sigmoid，但是在神经网络中需要做多次计算，反复计算z和a，最后计算损失函数（Loss Function）。<br>同时，在逻辑回归中有反向传播来计算导数da,dz等，在神经网络中同样也有这样的反向计算，如下图所示：<br><img src="https://s2.ax1x.com/2019/08/15/mAZsgJ.png" alt></p>
<h2 id="神经网络表示"><a href="#神经网络表示" class="headerlink" title="神经网络表示"></a>神经网络表示</h2><p>下图所示的神经网络由输入层，隐藏层和输出层构成，输入层是输入的训练集，y_hat是根据训练集输出的结果。<br><img src="https://s2.ax1x.com/2019/08/15/mAZWE6.png" alt><br>我们可以看到x和y_hat的值，但是看不到中间隐藏层神经元上的值。<br>之前使用向量x表示输入特征，输入特征的数值还有另外一种表示方式a\^[0]=x（[0]是上标）,同时，这个a也表示“激活”的意思，它意味着网络中不同层的值会传递给后面的层。</p>
<p>同理，隐藏层也会产生一些“激活”，因此，将其记作 a\^[1]，其中的四个神经元就分别对应着a\^[1]_1，a\^[1]_2等，其中，a\^[1]是一个四维向量。最终，输出层会产生某个数值a\^[2]，是个实数，所以 y_hat=a\^[2]。<br><img src="https://s2.ax1x.com/2019/08/15/mAZogH.png" alt></p>
<p>这和逻辑回归类似，但是在逻辑回归中则不需要上标来明确指出这些之来自哪一层。</p>
<p>最后，我们需要知道，隐藏层，以及最后的输入层是带有参数的。这里的隐藏层有两个相关的参数W和b，使用上标[1]来表示这些参数是和第一层这个隐藏层有关的。W是一个4x3的矩阵，b是一个4x1的向量。</p>
<p>最后输出层的W和b上标为2，W\^[2]的大小是1x4，b\^[2]的大小是1x1。</p>
<h2 id="计算神经网络的输出"><a href="#计算神经网络的输出" class="headerlink" title="计算神经网络的输出"></a>计算神经网络的输出</h2><p>本节以单个训练样本计算神经网络的预测为例。<br>当前神经元中包含两个计算步骤：<br>1.计算出z的值；<br>2.计算sigmoid函数。<br><img src="https://s2.ax1x.com/2019/08/16/mVOqne.png" alt></p>
<p>从单个神经元到神经网络，只是将单个神经元中的计算重复多次。<br>以上图左部的神经网络为例，首先计算最上面的神经元：<br><img src="https://s2.ax1x.com/2019/08/16/mVOL0H.png" alt></p>
<p>其中，上述的标号[1]都和第一隐层有关的向量，因为这是隐层的第一个节点，所有才有一个下标1。</p>
<p>现在来看第二层的计算：<br><img src="https://s2.ax1x.com/2019/08/16/mVXS9P.png" alt></p>
<p>完整的计算图以及向量化图示如下：<br><img src="https://s2.ax1x.com/2019/08/16/mVX9c8.png" alt><br>一层中的四个节点[z^[1]_1，z^[1]_2,z^[1]_3,z^[1]_4]堆叠起来用z^[1]来表示，W^\1]还有b^[1]也是类似的。最后a^[1]=sigmoid(z^[1])也就是表示将sigmoid计算作用到每个z上。</p>
<p>矩阵运算与推导细节如下，很容易能看懂，不再赘述计算过程。<br><img src="https://s2.ax1x.com/2019/08/16/mVXFBQ.png" alt><br>总结：对于逻辑回归，为了计算输出或者说预测，需要计算z=w.Tx+b和y_hat=a=sigmoid(z)，当你有一个神经网络，你需要在代码中实现的是上图右边的等式部分，可以把这看作是一个向量化的计算过程。</p>
<h2 id="多个例子中的向量化"><a href="#多个例子中的向量化" class="headerlink" title="多个例子中的向量化"></a>多个例子中的向量化</h2><p>本节主要介绍如何将不同训练样本向量化，如何将不同的训练样本堆叠起来放入矩阵的各列。<br>首先回顾一下上节的内容，计算式子如下：<br><img src="https://s2.ax1x.com/2019/08/16/mVXk7j.png" alt><br>将一个样本转换为m个样本之后最后的输出过程变化如下：<br><img src="https://s2.ax1x.com/2019/08/16/mVXucT.png" alt><br>圆括号里的值表示训练样本，比如a^<a href="i">2</a>表示第i个训练样本。<br>通过代码实现时，使用循环从1-m实现上述四个方程的计算：<br><img src="https://s2.ax1x.com/2019/08/16/mVXKjU.png" alt></p>
<p>但是，正如之前提到的一样，通过循环计算耗时量巨大，所有仍然需要将上述过程向量化。<br>简单来说，首先把m个x的样本堆叠为一个计算矩阵，后续的计算步骤则和之前类似，如下图所示：<br><img src="https://s2.ax1x.com/2019/08/16/mVXlB4.png" alt></p>
<p>其中，竖排紫色的点表示隐藏单元对第i个训练样本的激活函数，横向矩阵A则会扫过不同的训练样本来进行计算（横向表示输入的样本，竖向对应不同的输入特征）。</p>
<h2 id="向量化实现的解释"><a href="#向量化实现的解释" class="headerlink" title="向量化实现的解释"></a>向量化实现的解释</h2><p>具体的向量化实现解释可以看下面这张图：<br><img src="https://s2.ax1x.com/2019/08/16/mVX1HJ.png" alt><br>为了方便计算，认为b=0，消去b。</p>
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><font color="#0099ff"><br>假如需要搭建一个神经网络，可以选择的是，选择隐层里用那一个激活函数，还有神经网络的输出单元用什么激活函数。<br></font>

<p>在之前的课程里，a的值总是通过sigmoid(z)来得到，然而，tanh函数（双曲正切函数）：<br><img src="https://s2.ax1x.com/2019/08/16/mVX8E9.png" alt><br>从实际上来说，tanh函数实际上是sigmoid的平移版。<br>在运算中，将sigmoid换成tanh，效果要更好，因为tanh输出介于-1到1之间，激活函数的平均值就更接近0。<br>其中，sigmoid函数和tanh函数都由一个缺点，就是如果z非常大或非常小，那么导数的梯度，或者说这个函数的斜率可能就很小。所以，当z很大或很小的时候，函数的斜率很接近0，这样会拖慢梯度下降算法。</p>
<p>由于这些原因，机器学习中有一个工具，修正线性单元（ReLU）：<br><img src="https://s2.ax1x.com/2019/08/16/mVXGNR.png" alt><br>只要z为正，导数就是1，当z为负时，斜率为0。如果实际使用这个函数，z刚好为0时，导数是没有定义的。</p>
<p>选择激活函数的经验法则：<br>如果输出值是0和1（即二元分类），那么sigmoid函数很适合作为输出层的激活函数，然后其他所有单元都用ReLU，所谓的线性修正函数现在已经变成激活函数的默认选择了。<br>如果不确定隐藏层使用什么激活函数，就用ReLU。<br>正如上文中提到的，ReLU有一个缺点，z为负时导数值为0，但是ReLU还有另外一个版本，叫做带泄露的ReLU，当z为负时，函数不再为0。<br><img src="https://s2.ax1x.com/2019/08/16/mVXJ41.png" alt></p>
<h2 id="为什么需要非线性激活函数"><a href="#为什么需要非线性激活函数" class="headerlink" title="为什么需要非线性激活函数"></a>为什么需要非线性激活函数</h2><p>如果使用线性激活函数，神经网络只是把输入线性组合再输出。<br><img src="https://s2.ax1x.com/2019/08/16/mVXBHH.png" alt><br>假如只使用线性函数或没有激活函数，无论神经网络由多少层，神经网络在做的只是计算线性激活函数，如果以这样的方法，不如直接去掉隐藏层。<br>因此，如果在隐藏层中使用线性激活函数，输出层使用sigmoid，那么这个神经网络和没有任何隐藏层的标准逻辑回归时一样的。</p>
<h2 id="激活函数的导数"><a href="#激活函数的导数" class="headerlink" title="激活函数的导数"></a>激活函数的导数</h2><p>当对神经网络使用反向传播的时候，需要计算激活函数的斜率或者导数。<br>这节的内容很简单，sigmoid已经推导过很多次了，tanh的求导也很容易。<br>sigmoid函数求导<br><img src="https://s2.ax1x.com/2019/08/16/mVX2gf.png" alt><br>tanh函数求导<br><img src="https://s2.ax1x.com/2019/08/16/mVXfKS.png" alt><br>ReLU函数求导<br><img src="https://s2.ax1x.com/2019/08/16/mVXhDg.png" alt></p>
<h2 id="神经网络的梯度下降"><a href="#神经网络的梯度下降" class="headerlink" title="神经网络的梯度下降"></a>神经网络的梯度下降</h2><p>在浅层神经网络（这里指仅包含一个输入层，一个隐藏层还有一个输出层的神经网络）中包含的参数有：W[1]，b[1]，W[2]，b[2]。</p>
<p>给出另外一组参数值的定义：<br>nx=n[0],n[1],n[2]<br>n[0]：表示有多少输入特征；<br>n[1]：表示隐藏单元数目；<br>n[2]：表示输出单元数目。</p>
<p>在之前的栗子中只介绍过n[2]等于1的情况，矩阵W[1]的维度就是（n[1],n[0]），b[1]的维度是（n[1],1），就是一个列向量，W[2]的维度就是（n[2],n[1]）。<br><img src="https://s2.ax1x.com/2019/08/16/mVXIEj.png" alt><br>神经网络中前向传播和反向传播的推导过程<br><img src="https://s2.ax1x.com/2019/08/16/mVXHCq.png" alt></p>
<h2 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h2><p>在逻辑回归中可以将权重初始化为0，但是如果将神经网络的各参数数组全部初始化为0,再使用梯度下降算法，那会完全无效。</p>
<p>如果全部初始化为0，那么隐藏层和输出层中的权重将完全一样。<br>解决办法：使用随机初始化。<br><img src="https://s2.ax1x.com/2019/08/16/mVXjrF.png" alt></p>
<font color="#0099FF"><br>注：这里有一个问题，为什么要使用0.01，为什么不用100或者1000之类的数字？<br></font><br>实际上，习惯将矩阵初始化为非常非常小的随机值，因为，如果使用的是tanh或者sigmoid激活函数，或者在输出层有一个sigmoid函数，如果权重太大，当计算激活函数值时，要记住z[1]=W[1]x+b，然后a[1]是应用于z[1]的激活函数，如果W过大，那么z也就会很大。或者这些z值会很大或者很小，所以在这种情况下，结果最后可能落在tanh或sigmoid函数的平缓部分，梯度的斜率非常小，意味着梯度下降法会非常慢，学习就会很慢。<br><font color="#0099FF"><br>注：当计算只有一层的神经网络时，0.01会是个不错的选择，但是如果神经网络过大，则需要试试0.01以外的常数。<br></font>






      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/08/15/吴恩达神经网络与深度学习-Week-3-学习记录/" data-id="cl028w1ej006bxwuk94h94r9b" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/神经网络/">神经网络</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/08/16/吴恩达神经网络与深度学习-Week-4-学习记录/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          吴恩达神经网络与深度学习 Week-4 学习记录
        
      </div>
    </a>
  
  
    <a href="/2019/08/15/cs224n-Lecture-5-反向传播和项目建议/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cs224n-Lecture-5 反向传播和项目建议</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
    <h3 class="widget-title">联系方式</h3>
    <div class="widget">
	  <li><a>klausvon@163.com</a></li>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">目录</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CTF/">CTF</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/HTML/">HTML</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP-知识图谱/">NLP,知识图谱</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/VQA/">VQA</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/XSS漏洞学习/">XSS漏洞学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/代码审计/">代码审计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/开发/">开发</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学学习/">数学学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/漏洞学习/">漏洞学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境配置/">环境配置</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/神经网络/">神经网络</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CTF-Web/">CTF_Web</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HTML/">HTML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JavaScript/">JavaScript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ML/">ML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Model-Compression/">Model Compression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PHP/">PHP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQL-injection/">SQL_injection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VQA/">VQA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/XXE/">XXE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/凸包算法/">凸包算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/开发/">开发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数学学习/">数学学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据挖掘/">数据挖掘</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/环境配置/">环境配置</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/知识图谱/">知识图谱</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/神经网络/">神经网络</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithm/" style="font-size: 16px;">Algorithm</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/CTF-Web/" style="font-size: 18px;">CTF_Web</a> <a href="/tags/HTML/" style="font-size: 10px;">HTML</a> <a href="/tags/JavaScript/" style="font-size: 10px;">JavaScript</a> <a href="/tags/ML/" style="font-size: 12px;">ML</a> <a href="/tags/Model-Compression/" style="font-size: 10px;">Model Compression</a> <a href="/tags/NLP/" style="font-size: 20px;">NLP</a> <a href="/tags/PHP/" style="font-size: 10px;">PHP</a> <a href="/tags/Python/" style="font-size: 12px;">Python</a> <a href="/tags/SQL-injection/" style="font-size: 14px;">SQL_injection</a> <a href="/tags/VQA/" style="font-size: 10px;">VQA</a> <a href="/tags/XXE/" style="font-size: 10px;">XXE</a> <a href="/tags/凸包算法/" style="font-size: 10px;">凸包算法</a> <a href="/tags/大数据/" style="font-size: 10px;">大数据</a> <a href="/tags/开发/" style="font-size: 18px;">开发</a> <a href="/tags/数学学习/" style="font-size: 12px;">数学学习</a> <a href="/tags/数据挖掘/" style="font-size: 12px;">数据挖掘</a> <a href="/tags/环境配置/" style="font-size: 10px;">环境配置</a> <a href="/tags/知识图谱/" style="font-size: 18px;">知识图谱</a> <a href="/tags/神经网络/" style="font-size: 16px;">神经网络</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/02/25/Neo4j启动报错-INFO-Neo4j-Server-shutdown-initiated-by-request-解决方案/">Neo4j启动报错 INFO  Neo4j Server shutdown initiated by request 解决方案</a>
          </li>
        
          <li>
            <a href="/2022/01/12/单调栈的奇妙冒险/">单调栈的奇妙冒险</a>
          </li>
        
          <li>
            <a href="/2021/06/03/Basic-Understanding-of-Optimization/">Basic Understanding of Optimization</a>
          </li>
        
          <li>
            <a href="/2021/06/02/Why-Deep-Structure/">Why Deep Structure</a>
          </li>
        
          <li>
            <a href="/2021/05/23/Model-Compression-基本概念/">What is Model Compression</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    <div class="widget-wrap">
    <h3 class="widget-title">友情链接</h3>
    <div class="widget">
	 <a class="theme-link"  href="https://mteacher.top/"> martini's blog </a><span>&nbsp;&nbsp;</span>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 Klaus<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>