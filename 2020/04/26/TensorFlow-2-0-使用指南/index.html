<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>TensorFlow 2.0 使用指南 (2020.5.4完结) | Klaus&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="前后大概花了一周半的时间把TensorFlow2.0的框架学完，这个版本相较于1.0在代码上要更加易于理解和操作。所以这里用这篇博客来记录 TensorFlow 2.0 中的各种操作细节，算是个人备忘录版的使用指南吧。">
<meta name="keywords" content="NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow 2.0 使用指南 (2020.5.4完结)">
<meta property="og:url" content="http://yoursite.com/2020/04/26/TensorFlow-2-0-使用指南/index.html">
<meta property="og:site_name" content="Klaus&#39;s Blog">
<meta property="og:description" content="前后大概花了一周半的时间把TensorFlow2.0的框架学完，这个版本相较于1.0在代码上要更加易于理解和操作。所以这里用这篇博客来记录 TensorFlow 2.0 中的各种操作细节，算是个人备忘录版的使用指南吧。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/26/Jcvy34.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/26/J2tlWt.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/26/J2dvVS.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/26/JRAVmT.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/28/JhfbUe.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/28/JhhmrV.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/28/Jhh82R.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/28/Jh4lef.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/28/Jh4ayq.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/28/Jh46fJ.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/29/JoDZQK.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/29/JoDDWq.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/29/JTSXQA.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/29/JTvJte.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/29/JHih5t.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/30/JqZ4Gd.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/30/JqZxRs.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/30/Jqn4G4.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/30/Jq4go9.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/30/JLd1aD.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/30/JLdWLV.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/05/04/YCXkXq.png">
<meta property="og:updated_time" content="2020-05-04T13:09:30.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow 2.0 使用指南 (2020.5.4完结)">
<meta name="twitter:description" content="前后大概花了一周半的时间把TensorFlow2.0的框架学完，这个版本相较于1.0在代码上要更加易于理解和操作。所以这里用这篇博客来记录 TensorFlow 2.0 中的各种操作细节，算是个人备忘录版的使用指南吧。">
<meta name="twitter:image" content="https://s1.ax1x.com/2020/04/26/Jcvy34.png">
  
    <link rel="alternate" href="/atom.xml" title="Klaus&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Klaus&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">MIA SAN MIA</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-TensorFlow-2-0-使用指南" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/04/26/TensorFlow-2-0-使用指南/" class="article-date">
  <time datetime="2020-04-26T06:06:19.000Z" itemprop="datePublished">2020-04-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      TensorFlow 2.0 使用指南 (2020.5.4完结)
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  <!-- Table of Contents -->
		
		  <div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据预处理"><span class="toc-number">1.</span> <span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#tf框架自带的数据集"><span class="toc-number">1.1.</span> <span class="toc-text">tf框架自带的数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sklearn自带的数据集"><span class="toc-number">1.2.</span> <span class="toc-text">sklearn自带的数据集</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据加载和预处理"><span class="toc-number">2.</span> <span class="toc-text">数据加载和预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#csv数据处理"><span class="toc-number">2.1.</span> <span class="toc-text">csv数据处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#x-label处理方式一：tf-data-experimental-make-csv-dataset"><span class="toc-number">2.1.1.</span> <span class="toc-text">x,label处理方式一：tf.data.experimental.make_csv_dataset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#x-label处理方式二-pandas"><span class="toc-number">2.1.2.</span> <span class="toc-text">x,label处理方式二:pandas</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#离散型特征"><span class="toc-number">2.1.3.</span> <span class="toc-text">离散型特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#连续型数据处理"><span class="toc-number">2.1.4.</span> <span class="toc-text">连续型数据处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#创建预处理层"><span class="toc-number">2.1.5.</span> <span class="toc-text">创建预处理层</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型构建，训练与评估"><span class="toc-number">2.2.</span> <span class="toc-text">模型构建，训练与评估</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#tf处理数据版泰坦尼克生存预测模型完整代码"><span class="toc-number">2.2.1.</span> <span class="toc-text">tf处理数据版泰坦尼克生存预测模型完整代码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#pandas处理数据版泰坦尼克生存预测模型完整代码"><span class="toc-number">2.2.2.</span> <span class="toc-text">pandas处理数据版泰坦尼克生存预测模型完整代码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#总结"><span class="toc-number">2.2.3.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#numpy数据预处理"><span class="toc-number">2.3.</span> <span class="toc-text">numpy数据预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#图像数据处理"><span class="toc-number">2.4.</span> <span class="toc-text">图像数据处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#文本数据处理"><span class="toc-number">2.5.</span> <span class="toc-text">文本数据处理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Estimator"><span class="toc-number">3.</span> <span class="toc-text">Estimator</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#预创建的Estimator"><span class="toc-number">3.1.</span> <span class="toc-text">预创建的Estimator</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Keras模型转Estimator"><span class="toc-number">3.2.</span> <span class="toc-text">Keras模型转Estimator</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#自定义"><span class="toc-number">4.</span> <span class="toc-text">自定义</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#张量和操作"><span class="toc-number">4.1.</span> <span class="toc-text">张量和操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#张量的基本计算"><span class="toc-number">4.1.1.</span> <span class="toc-text">张量的基本计算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Numpy和Tensor的相互转换"><span class="toc-number">4.1.2.</span> <span class="toc-text">Numpy和Tensor的相互转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#设置运行设备"><span class="toc-number">4.1.3.</span> <span class="toc-text">设置运行设备</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#自定义层"><span class="toc-number">4.2.</span> <span class="toc-text">自定义层</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积神经网络实现"><span class="toc-number">5.</span> <span class="toc-text">卷积神经网络实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CNN实现图像分类"><span class="toc-number">5.1.</span> <span class="toc-text">CNN实现图像分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CNN实现文本分类"><span class="toc-number">5.2.</span> <span class="toc-text">CNN实现文本分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#循环神经网络实现"><span class="toc-number">6.</span> <span class="toc-text">循环神经网络实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#普通RNN实现"><span class="toc-number">6.1.</span> <span class="toc-text">普通RNN实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Padding-Pooling"><span class="toc-number">6.2.</span> <span class="toc-text">Padding_Pooling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#双向RNN"><span class="toc-number">6.3.</span> <span class="toc-text">双向RNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LSTM"><span class="toc-number">6.4.</span> <span class="toc-text">LSTM</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#模型保存"><span class="toc-number">7.</span> <span class="toc-text">模型保存</span></a></li></ol>
		  </div>
		
        <p>前后大概花了一周半的时间把TensorFlow2.0的框架学完，这个版本相较于1.0在代码上要更加易于理解和操作。<br>所以这里用这篇博客来记录 TensorFlow 2.0 中的各种操作细节，算是个人备忘录版的使用指南吧。<br><a id="more"></a></p>
<p>本篇博客会按照数据处理，Estimator，模型保存，CNN及其实践，RNN及其实践，注意力机制等几个部分来撰写。<br>p.s. 以前开发做点Python相关的东西还是习惯用Pycharm，不过学习这个框架的过程中由于需要清晰的看到每个步骤的结果，所以用了一下Jupyter，害，用户体验嘛，那当然是极好的！以后做神经网络模型这类型的，我可能会继续沿用Jupyter，不过如果项目规模偏大，那还是回到Pycharm。btw,VScode编写ipynb体验还不错。</p>
<p><b>注：本篇博客参考内容主要来自于<a href="https://www.tensorflow.org/tutorials?hl=zh-cn" target="_blank" rel="noopener">TF2.1.0官网的教程</a>，部分内容有参考相关学习过的内容，结合这二者写完这篇笔记。</b></p>
<p>最后，全文实现的代码都是在Jupyter上写的。</p>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>以我个人的看法，数据预处理这部分内容在神经网络的构建中可以说是极其重要的。如果没有处理好数据，并生成用以训练的向量，那这个模型基本白搭，所以这块的内容我会尽量去详细的记录。</p>
<h3 id="tf框架自带的数据集"><a href="#tf框架自带的数据集" class="headerlink" title="tf框架自带的数据集"></a>tf框架自带的数据集</h3><p>tf框架最常见的自带数据集包括：mnist,fashion_minist，imbd等，这类数据集最大的好处就是自带切分功能。<br>引用方式通常比较简单，并且已经是向量化的数据，以这里取出来的数据来说，就是一张大小为28x28的图像各个像素点的值。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"><span class="keyword">from</span> tensorflow import keras</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接获取数据</span></span><br><span class="line"><span class="attribute">mnist</span>=keras.datasets.mnist</span><br><span class="line">(x_train_all,y_train_all),(x_test,y_test)=mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切分训练集和验证集</span></span><br><span class="line">x_train,<span class="attribute">y_train</span>=x_train_all[:5000],y_train_all[:5000]</span><br><span class="line">x_valid,<span class="attribute">y_valid</span>=x_train_all[5000:],y_train_all[5000:]</span><br></pre></td></tr></table></figure></p>
<h3 id="sklearn自带的数据集"><a href="#sklearn自带的数据集" class="headerlink" title="sklearn自带的数据集"></a>sklearn自带的数据集</h3><p>sklearn下的数据集类似于tf下面的，不过需要额外引入另外的两个包，一个负责取出数据集，一个负责对训练集和测试集进行分割。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets import fetch_california_housing # 取出数据集</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection import train_test_split # 对数据集进行分割</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取出相应的数据集</span></span><br><span class="line"><span class="attribute">housing</span>=fetch_california_housing()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印出相关信息</span></span><br><span class="line"><span class="builtin-name">print</span>(housing.DESCR) # 数据描述</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'----------------'</span>)</span><br><span class="line"><span class="builtin-name">print</span>(housing.data.shape) # 数据大小</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'----------------'</span>)</span><br><span class="line"><span class="builtin-name">print</span>(housing.target.shape) # label</span><br><span class="line"></span><br><span class="line">x_train_all, x_test, y_train_all, y_test = train_test_split(</span><br><span class="line">    housing.data, housing.target, random_state = 7)</span><br><span class="line">x_train, x_valid, y_train, y_valid = train_test_split(</span><br><span class="line">    x_train_all, y_train_all, random_state = 11)</span><br><span class="line"><span class="builtin-name">print</span>(x_train.shape, y_train.shape)</span><br><span class="line"><span class="builtin-name">print</span>(x_valid.shape, y_valid.shape)</span><br><span class="line"><span class="builtin-name">print</span>(x_test.shape, y_test.shape)</span><br></pre></td></tr></table></figure></p>
<h2 id="数据加载和预处理"><a href="#数据加载和预处理" class="headerlink" title="数据加载和预处理"></a>数据加载和预处理</h2><p>以我过去从事NLP文本分类的经验，单从上面两个包中提供的数据集不满足实验需求，不同的文章中使用到的数据集不一样，所以还需要具备处理其他数据集的能力。</p>
<h3 id="csv数据处理"><a href="#csv数据处理" class="headerlink" title="csv数据处理"></a>csv数据处理</h3><h4 id="x-label处理方式一：tf-data-experimental-make-csv-dataset"><a href="#x-label处理方式一：tf-data-experimental-make-csv-dataset" class="headerlink" title="x,label处理方式一：tf.data.experimental.make_csv_dataset"></a>x,label处理方式一：tf.data.experimental.make_csv_dataset</h4><p>这里直接使用这俩数据集（泰坦尼克号生存数据集），下载地址如下：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">http<span class="variable">s:</span>//storage.googleapis.<span class="keyword">com</span>/<span class="keyword">tf</span>-datasets/titanic/train.csv</span><br><span class="line">http<span class="variable">s:</span>//storage.googleapis.<span class="keyword">com</span>/<span class="keyword">tf</span>-datasets/titanic/<span class="built_in">eval</span>.csv</span><br></pre></td></tr></table></figure></p>
<p>下载下来以后单独保存在一个 dataset 文件夹下面，下载完成以后，有两种方法可以查看csv中数据集包含的数据：<br><b>1. 使用pandas</b><br>关于pandas部分库的操作，之前我写过一篇笔记，可以作为参考：<a href="http://klausvon.cn/2018/10/05/Python-%E8%AF%BB%E5%86%99csv%E6%96%87%E4%BB%B6%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/" target="_blank" rel="noopener">Python 读写csv文件相关操作</a></p>
<p>这里直接取出列表名称,和相关数据<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">file</span>=pd.read_csv(<span class="string">'./dataset/train.csv'</span>)</span><br><span class="line"><span class="keyword">print</span>(<span class="keyword">list</span>(<span class="keyword">file</span>.head()))#列表名称</span><br><span class="line"><span class="keyword">print</span>(<span class="keyword">file</span>.head())#列表数据</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/26/Jcvy34.png" alt></p>
<p><b>2. 直接在Jupyter的环境下查看</b><br><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="addition">!head &#123;文件路径&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>这些取出来的列名参数需要传参给tf.data.experimental.make_csv_dataset下面的column_names参数。<br>使用这个包和取出的列名来构造可以用于基于TensorFlow搭建模型的训练和测试数据。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow_datasets as tfds</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"><span class="attribute">file_path</span>=<span class="string">'./dataset/train.csv'</span></span><br><span class="line"><span class="attribute">file</span>=pd.read_csv(file_path)</span><br><span class="line"><span class="attribute">csv_columns</span>=list(file.head())</span><br><span class="line"><span class="builtin-name">print</span>(csv_columns)#列表名称</span><br><span class="line"><span class="builtin-name">print</span>(file.head())#列表数据</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 label</span></span><br><span class="line"><span class="attribute">label_culomn</span>=<span class="string">'survived'</span></span><br><span class="line">labels=[0,1]</span><br><span class="line"></span><br><span class="line">def get_dataset(file_path):</span><br><span class="line">    <span class="attribute">dataset</span>=tf.data.experimental.make_csv_dataset(</span><br><span class="line">        file_path,</span><br><span class="line">        <span class="attribute">batch_size</span>=12,</span><br><span class="line">        <span class="attribute">label_name</span>=label_culomn,# 取出某列的数据作为label</span><br><span class="line">        <span class="attribute">na_value</span>=<span class="string">'?'</span>,# 识别NA/NaN的附加字符串,设置为?</span><br><span class="line">        <span class="attribute">num_epochs</span>=1,# 遍历数据集的次数</span><br><span class="line">        <span class="attribute">ignore_errors</span>=<span class="literal">True</span>)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成的值类型为:</span></span><br><span class="line"><span class="comment"># &lt;class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'&gt;</span></span><br><span class="line"><span class="comment"># 如果想查看其中的内容,可以使用iter进行迭代,通过next嵌套iter可以查看第一轮运行的数据</span></span><br><span class="line"><span class="comment"># 第一轮运行数据的大小取决于设置的batch_size</span></span><br><span class="line"><span class="attribute">raw_train_data</span>=get_dataset(file_path) </span><br><span class="line"><span class="attribute">raw_test_data</span>=get_dataset(file_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的数据集中的样本和标签</span></span><br><span class="line">example,<span class="attribute">label</span>=next(iter(raw_train_data))</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'Example:'</span>,example) # sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'Label:'</span>,label) # label:survived</span><br></pre></td></tr></table></figure></p>
<p>输出值如下：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Example:OrderedDict([(<span class="string">'sex'</span>, &lt;tf.Tensor: shape=(12,), <span class="attribute">dtype</span>=string, numpy=</span><br><span class="line">array([b<span class="string">'male'</span>, b<span class="string">'female'</span>, b<span class="string">'male'</span>, b<span class="string">'male'</span>, b<span class="string">'male'</span>, b<span class="string">'female'</span>, b<span class="string">'male'</span>,</span><br><span class="line">       b<span class="string">'male'</span>, b<span class="string">'female'</span>, b<span class="string">'male'</span>, b<span class="string">'male'</span>, b<span class="string">'female'</span>], <span class="attribute">dtype</span>=object)&gt;), (<span class="string">'age'</span>, &lt;tf.Tensor: shape=(12,), <span class="attribute">dtype</span>=float32, numpy=</span><br><span class="line">array([28. , 28. , 21. , 26. , 45. , 31. , 28. , 18. , 28. , 43. , 32.5,</span><br><span class="line">       58. ], <span class="attribute">dtype</span>=float32)&gt;), (<span class="string">'n_siblings_spouses'</span>, &lt;tf.Tensor: shape=(12,), <span class="attribute">dtype</span>=int32, <span class="attribute">numpy</span>=array([0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0])&gt;), (<span class="string">'parch'</span>, &lt;tf.Tensor: shape=(12,), <span class="attribute">dtype</span>=int32, <span class="attribute">numpy</span>=array([0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1])&gt;), (<span class="string">'fare'</span>, &lt;tf.Tensor: shape=(12,), <span class="attribute">dtype</span>=float32, numpy=</span><br><span class="line">array([ 35.5   , 133.65  ,  73.5   ,   8.05  ,   8.05  , 164.8667,</span><br><span class="line">        56.4958,   7.7958,  14.4542,  26.25  ,  30.0708, 153.4625],</span><br><span class="line">      <span class="attribute">dtype</span>=float32)&gt;), (<span class="string">'class'</span>, &lt;tf.Tensor: shape=(12,), <span class="attribute">dtype</span>=string, numpy=</span><br><span class="line">array([b<span class="string">'First'</span>, b<span class="string">'First'</span>, b<span class="string">'Second'</span>, b<span class="string">'Third'</span>, b<span class="string">'Third'</span>, b<span class="string">'First'</span>,</span><br><span class="line">       b<span class="string">'Third'</span>, b<span class="string">'Third'</span>, b<span class="string">'Third'</span>, b<span class="string">'Second'</span>, b<span class="string">'Second'</span>, b<span class="string">'First'</span>],</span><br><span class="line">      <span class="attribute">dtype</span>=object)&gt;), (<span class="string">'deck'</span>, &lt;tf.Tensor: shape=(12,), <span class="attribute">dtype</span>=string, numpy=</span><br><span class="line">array([b<span class="string">'A'</span>, b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'C'</span>,</span><br><span class="line">       b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'C'</span>],</span><br><span class="line">      <span class="attribute">dtype</span>=object)&gt;), (<span class="string">'embark_town'</span>, &lt;tf.Tensor: shape=(12,), <span class="attribute">dtype</span>=string, numpy=</span><br><span class="line">array([b<span class="string">'Southampton'</span>, b<span class="string">'Southampton'</span>, b<span class="string">'Southampton'</span>, b<span class="string">'Southampton'</span>,</span><br><span class="line">       b<span class="string">'Southampton'</span>, b<span class="string">'Southampton'</span>, b<span class="string">'Southampton'</span>, b<span class="string">'Southampton'</span>,</span><br><span class="line">       b<span class="string">'Cherbourg'</span>, b<span class="string">'Southampton'</span>, b<span class="string">'Cherbourg'</span>, b<span class="string">'Southampton'</span>],</span><br><span class="line">      <span class="attribute">dtype</span>=object)&gt;), (<span class="string">'alone'</span>, &lt;tf.Tensor: shape=(12,), <span class="attribute">dtype</span>=string, numpy=</span><br><span class="line">array([b<span class="string">'y'</span>, b<span class="string">'n'</span>, b<span class="string">'y'</span>, b<span class="string">'y'</span>, b<span class="string">'y'</span>, b<span class="string">'n'</span>, b<span class="string">'y'</span>, b<span class="string">'y'</span>, b<span class="string">'n'</span>, b<span class="string">'n'</span>, b<span class="string">'n'</span>,</span><br><span class="line">       b<span class="string">'n'</span>], <span class="attribute">dtype</span>=object)&gt;)])</span><br><span class="line">Label:tf.Tensor([1 1 0 0 1 1 1 0 0 0 0 1], shape=(12,), <span class="attribute">dtype</span>=int32)</span><br></pre></td></tr></table></figure></p>
<p>这里有个问题，如何单独查看example或者label中的值，这个很简单，这两个值类似于字典类型，以example举例子，取出age这一栏，并通过numpy形式展示：<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="name">example</span>['age'].numpy())</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/26/J2tlWt.png" alt></p>
<h4 id="x-label处理方式二-pandas"><a href="#x-label处理方式二-pandas" class="headerlink" title="x,label处理方式二:pandas"></a>x,label处理方式二:pandas</h4><p>基于pandas读取出来的csv文件可以直接使用pop函数来取出某个单独列的值。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"><span class="attribute">train_df</span>=pd.read_csv('./dataset/train.csv')</span><br><span class="line"><span class="attribute">eval_df</span>=pd.read_csv('./dataset/eval.csv')</span><br><span class="line"></span><br><span class="line"><span class="attribute">y_train</span>=train_df.pop('survived')</span><br><span class="line"><span class="attribute">y_eval</span>=eval_df.pop('survived')</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'train_df.shape:'</span>,train_df.shape)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'eval_df.shape:'</span>,eval_df.shape)</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/26/J2dvVS.png" alt></p>
<p>pandas在划分x和y的时候相对比之前tf.data.experimental.make_csv_dataset要简便不少，同时，取出的pandas Series数据可以在外嵌套一层numpy.array()就可以转换为numpy类型的array,然后通过reshape转换成模型需要的任意大小：<br><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="title">new_train_df</span>=np.array(train_df).reshape([<span class="number">-1</span>,])</span><br></pre></td></tr></table></figure></p>
<h4 id="离散型特征"><a href="#离散型特征" class="headerlink" title="离散型特征"></a>离散型特征</h4><p>上面介绍了两种对数据进行划分的方法，下面继续对数据进行分类。<br>这里直接引用官方文档的话：<br>csv数据中的有些列是分类的列，也就是说，这些列只能在有限的集合中取值。(这些列也就相当于是已经提取好的特征值)</p>
<p>使用 tf.feature_column API创建一个 tf.feature_column.indicator_column 集合，每个 tf.feature_column.indicator_column对应一个分类的列。</p>
<p>核心api：<br><b><br>tf.feature_column.categorical_column_with_vocabulary_list<br>tf.feature_column.indicator_column<br></b></p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里分类仅使用几个特征列</span></span><br><span class="line">categories = &#123;</span><br><span class="line">    <span class="string">'sex'</span>: [<span class="string">'male'</span>, <span class="string">'female'</span>],</span><br><span class="line">    <span class="string">'class'</span> : [<span class="string">'First'</span>, <span class="string">'Second'</span>, <span class="string">'Third'</span>],</span><br><span class="line">    <span class="string">'deck'</span> : [<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>, <span class="string">'D'</span>, <span class="string">'E'</span>, <span class="string">'F'</span>, <span class="string">'G'</span>, <span class="string">'H'</span>, <span class="string">'I'</span>, <span class="string">'J'</span>],</span><br><span class="line">    <span class="string">'embark_town'</span> : [<span class="string">'Cherbourg'</span>, <span class="string">'Southhampton'</span>, <span class="string">'Queenstown'</span>],</span><br><span class="line">    <span class="string">'alone'</span> : [<span class="string">'y'</span>, <span class="string">'n'</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">categorical_columns=[]</span><br><span class="line"><span class="keyword">for</span> feature,vocab <span class="keyword">in</span> catecategories.items():</span><br><span class="line">    <span class="attribute">cat_col</span>=tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        <span class="attribute">key</span>=feature,</span><br><span class="line">        <span class="attribute">vocabulary_list</span>=vocab)</span><br><span class="line">    categorical_columns.append(tf.feature_column.indicator_column(cat_col))</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(categorical_columns)</span><br></pre></td></tr></table></figure>
<h4 id="连续型数据处理"><a href="#连续型数据处理" class="headerlink" title="连续型数据处理"></a>连续型数据处理</h4><p>处理完分类数据之后需要处理连续数据.主要需要进行归一化处理.</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def process_continuous_data(mean,data):</span><br><span class="line">    # 标准化数据</span><br><span class="line">    # <span class="keyword">tf</span>.cas<span class="variable">t:</span>转换数据格式</span><br><span class="line">    data=<span class="keyword">tf</span>.cast(data,<span class="keyword">tf</span>.float32)*<span class="number">1</span>/(<span class="number">2</span>*mean)</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">tf</span>.reshape(data,[-<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">	</span><br><span class="line">MEANS = &#123;</span><br><span class="line">    <span class="string">'age'</span> : <span class="number">29.631308</span>,</span><br><span class="line">    <span class="string">'n_siblings_spouses'</span> : <span class="number">0.545455</span>,</span><br><span class="line">    <span class="string">'parch'</span> : <span class="number">0.379585</span>,</span><br><span class="line">    <span class="string">'fare'</span> : <span class="number">34.385399</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">numerical_columns=[]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature in MEANS.<span class="built_in">keys</span>():</span><br><span class="line">    num_col=<span class="keyword">tf</span>.feature_column.numeric_column(</span><br><span class="line">        feature,</span><br><span class="line">        normalizer_fn=functools.partial(process_continuous_data,MEANS[feature]))</span><br><span class="line">    numerical_columns.<span class="keyword">append</span>(num_col)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span>(numerical_columns)</span><br></pre></td></tr></table></figure>
<p>输出的结果就是各个连续值特征归一化的值:<br><img src="https://s1.ax1x.com/2020/04/26/JRAVmT.png" alt></p>
<h4 id="创建预处理层"><a href="#创建预处理层" class="headerlink" title="创建预处理层"></a>创建预处理层</h4><p>上面分别介绍了 离散型特征 和 连续型特征 的处理方法，现在需要对两类型的特征进行合并，从而创建一个能进行预处理的输入层。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">preprocessing_layer</span> = tf.keras.layers.DenseFeatures(categorical_columns+numerical_columns)</span><br></pre></td></tr></table></figure>
<h3 id="模型构建，训练与评估"><a href="#模型构建，训练与评估" class="headerlink" title="模型构建，训练与评估"></a>模型构建，训练与评估</h3><p>这里暂时先插一句，在tf2.0的版本中，调用构建神经网络中各种层都是使用 tf.keras.layers 来进行构建。<br>同时，由于这是一个Sequential模型，所以要使用 tf.keras.Sequential 方法来创建。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">model</span>=tf.keras.Sequential([</span><br><span class="line">    preprocessing_layer,</span><br><span class="line">    tf.keras.layers.Dense(128,<span class="attribute">activation</span>=<span class="string">'relu'</span>),# 基于特征层的基础上构建全连接层</span><br><span class="line">    tf.keras.layers.Dense(128,<span class="attribute">activation</span>=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.Dense(1,<span class="attribute">activation</span>=<span class="string">'sigmoid'</span>)# 最后只需要预测一个结果</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    <span class="attribute">loss</span>=<span class="string">'binary_crossentropy'</span>,# 定义损失函数</span><br><span class="line">    <span class="attribute">optimizer</span>=<span class="string">'adam'</span>,# 定义优化器</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])# 定义衡量结果的标准</span><br><span class="line">	</span><br><span class="line"><span class="attribute">train_data</span>=raw_train_data.shuffle(500) # 打乱数据</span><br><span class="line"><span class="attribute">test_data</span>=raw_test_data</span><br><span class="line"></span><br><span class="line">model.fit(train_data,<span class="attribute">epochs</span>=20) # 训练模型</span><br><span class="line"></span><br><span class="line">test_loss, test_accuracy = model.evaluate(test_data) # 测试模型</span><br><span class="line"><span class="builtin-name">print</span>(test_loss)</span><br><span class="line"><span class="builtin-name">print</span>(test_accuracy)</span><br></pre></td></tr></table></figure></p>
<h4 id="tf处理数据版泰坦尼克生存预测模型完整代码"><a href="#tf处理数据版泰坦尼克生存预测模型完整代码" class="headerlink" title="tf处理数据版泰坦尼克生存预测模型完整代码"></a>tf处理数据版泰坦尼克生存预测模型完整代码</h4><p>上面为了分步描述步骤，写得比较简略，这里贴上一个完整版以供参考。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow_datasets as tfds</span><br><span class="line">import pandas as pd</span><br><span class="line">import functools</span><br><span class="line"></span><br><span class="line"><span class="attribute">file_path</span>=<span class="string">'./dataset/train.csv'</span></span><br><span class="line"><span class="attribute">file</span>=pd.read_csv(file_path)</span><br><span class="line"><span class="attribute">csv_columns</span>=list(file.head())</span><br><span class="line"><span class="builtin-name">print</span>(csv_columns)#列表名称</span><br><span class="line"><span class="builtin-name">print</span>(file.head())#列表数据</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 label</span></span><br><span class="line"><span class="attribute">label_culomn</span>=<span class="string">'survived'</span></span><br><span class="line">labels=[0,1]</span><br><span class="line"></span><br><span class="line">def get_dataset(file_path):</span><br><span class="line">    <span class="attribute">dataset</span>=tf.data.experimental.make_csv_dataset(</span><br><span class="line">        file_path,</span><br><span class="line">        <span class="attribute">batch_size</span>=12,</span><br><span class="line">        <span class="attribute">label_name</span>=label_culomn,# 取出某列的数据作为label</span><br><span class="line">        <span class="attribute">na_value</span>=<span class="string">'?'</span>,# 识别NA/NaN的附加字符串,设置为?</span><br><span class="line">        <span class="attribute">num_epochs</span>=1,# 遍历数据集的次数</span><br><span class="line">        <span class="attribute">ignore_errors</span>=<span class="literal">True</span>)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成的值类型为:</span></span><br><span class="line"><span class="comment"># &lt;class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'&gt;</span></span><br><span class="line"><span class="comment"># 如果想查看其中的内容,可以使用iter进行迭代,通过next嵌套iter可以查看第一轮运行的数据</span></span><br><span class="line"><span class="comment"># 第一轮运行数据的大小取决于设置的batch_size</span></span><br><span class="line"><span class="attribute">raw_train_data</span>=get_dataset(file_path) </span><br><span class="line"><span class="attribute">raw_test_data</span>=get_dataset(file_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的数据集中的样本和标签</span></span><br><span class="line">example,<span class="attribute">label</span>=next(iter(raw_train_data))</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'Example:'</span>,example) # sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'Label:'</span>,label) # label:survived</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理离散型特征</span></span><br><span class="line">categories = &#123;</span><br><span class="line">    <span class="string">'sex'</span>: [<span class="string">'male'</span>, <span class="string">'female'</span>],</span><br><span class="line">    <span class="string">'class'</span> : [<span class="string">'First'</span>, <span class="string">'Second'</span>, <span class="string">'Third'</span>],</span><br><span class="line">    <span class="string">'deck'</span> : [<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>, <span class="string">'D'</span>, <span class="string">'E'</span>, <span class="string">'F'</span>, <span class="string">'G'</span>, <span class="string">'H'</span>, <span class="string">'I'</span>, <span class="string">'J'</span>],</span><br><span class="line">    <span class="string">'embark_town'</span> : [<span class="string">'Cherbourg'</span>, <span class="string">'Southhampton'</span>, <span class="string">'Queenstown'</span>],</span><br><span class="line">    <span class="string">'alone'</span> : [<span class="string">'y'</span>, <span class="string">'n'</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">categorical_columns=[]</span><br><span class="line"><span class="keyword">for</span> feature,vocab <span class="keyword">in</span> catecategories.items():</span><br><span class="line">    <span class="attribute">cat_col</span>=tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        <span class="attribute">key</span>=feature,</span><br><span class="line">        <span class="attribute">vocabulary_list</span>=vocab)</span><br><span class="line">    categorical_columns.append(tf.feature_column.indicator_column(cat_col))</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(categorical_columns)</span><br><span class="line"></span><br><span class="line">def process_continuous_data(mean,data):</span><br><span class="line">    # 标准化数据</span><br><span class="line">    # tf.cast:转换数据格式</span><br><span class="line">    <span class="attribute">data</span>=tf.cast(data,tf.float32)*1/(2*mean)</span><br><span class="line">    return tf.reshape(data,[-1,1])</span><br><span class="line"></span><br><span class="line">MEANS = &#123;</span><br><span class="line">    <span class="string">'age'</span> : 29.631308,</span><br><span class="line">    <span class="string">'n_siblings_spouses'</span> : 0.545455,</span><br><span class="line">    <span class="string">'parch'</span> : 0.379585,</span><br><span class="line">    <span class="string">'fare'</span> : 34.385399</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">numerical_columns=[]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> MEANS.keys():</span><br><span class="line">    <span class="attribute">num_col</span>=tf.feature_column.numeric_column(</span><br><span class="line">        feature,</span><br><span class="line">        <span class="attribute">normalizer_fn</span>=functools.partial(process_continuous_data,MEANS[feature]))</span><br><span class="line">    numerical_columns.append(num_col)</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(numerical_columns)</span><br><span class="line"></span><br><span class="line">preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numerical_columns)</span><br><span class="line"></span><br><span class="line"><span class="attribute">model</span>=tf.keras.Sequential([</span><br><span class="line">    preprocessing_layer,</span><br><span class="line">    tf.keras.layers.Dense(128,<span class="attribute">activation</span>=<span class="string">'relu'</span>),# 基于特征层的基础上构建全连接层</span><br><span class="line">    tf.keras.layers.Dense(128,<span class="attribute">activation</span>=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.Dense(1,<span class="attribute">activation</span>=<span class="string">'sigmoid'</span>)# 最后只需要预测一个结果</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    <span class="attribute">loss</span>=<span class="string">'binary_crossentropy'</span>,# 定义损失函数</span><br><span class="line">    <span class="attribute">optimizer</span>=<span class="string">'adam'</span>,# 定义优化器</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])# 定义衡量结果的标准</span><br><span class="line">	</span><br><span class="line"><span class="attribute">train_data</span>=raw_train_data.shuffle(500) # 打乱数据</span><br><span class="line"><span class="attribute">test_data</span>=raw_test_data</span><br><span class="line"></span><br><span class="line">model.fit(train_data,<span class="attribute">epochs</span>=20)</span><br><span class="line"></span><br><span class="line">test_loss, test_accuracy = model.evaluate(test_data) # 测试模型</span><br><span class="line"><span class="builtin-name">print</span>(test_loss)</span><br><span class="line"><span class="builtin-name">print</span>(test_accuracy)</span><br></pre></td></tr></table></figure>
<h4 id="pandas处理数据版泰坦尼克生存预测模型完整代码"><a href="#pandas处理数据版泰坦尼克生存预测模型完整代码" class="headerlink" title="pandas处理数据版泰坦尼克生存预测模型完整代码"></a>pandas处理数据版泰坦尼克生存预测模型完整代码</h4><p>私以为这个版本比上面那个版本更容易理解一些，不过在处理特征上的区别不是很大。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib as mpl</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import sklearn</span><br><span class="line">import pandas as pd</span><br><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">import time</span><br><span class="line">import tensorflow as tf</span><br><span class="line"><span class="keyword">from</span> tensorflow import keras</span><br><span class="line"></span><br><span class="line"><span class="attribute">train_file</span>=<span class="string">'./dataset/train.csv'</span></span><br><span class="line"><span class="attribute">eval_file</span>=<span class="string">'./dataset/eval.csv'</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">train_df</span>=pd.read_csv(train_file)</span><br><span class="line"><span class="attribute">eval_df</span>=pd.read_csv(eval_file)</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(train_df.head())</span><br><span class="line"><span class="builtin-name">print</span>(eval_df.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取出survived字段作为label</span></span><br><span class="line"><span class="attribute">y_train</span>=train_df.pop('survived')</span><br><span class="line"><span class="attribute">y_eval</span>=eval_df.pop('survived')</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(y_train.head())</span><br><span class="line"><span class="builtin-name">print</span>(y_eval.head())</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(train_df.shape)</span><br><span class="line"><span class="builtin-name">print</span>(eval_df.shape)</span><br><span class="line"></span><br><span class="line">feature_columns=[]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理离散型特征</span></span><br><span class="line">categorical_columns=[<span class="string">'sex'</span>,<span class="string">'n_siblings_spouses'</span>,<span class="string">'parch'</span>,</span><br><span class="line">    <span class="string">'class'</span>,<span class="string">'deck'</span>,<span class="string">'embark_town'</span>,<span class="string">'alone'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> categorical_column <span class="keyword">in</span> categorical_columns:</span><br><span class="line">    # 取出离散型特征对应的值并去重</span><br><span class="line">    <span class="attribute">vocab</span>=train_df[categorical_column].unique()</span><br><span class="line">    # 使用 tensorflow 来定义离散特征 categorical_column_with_vocabulary_list</span><br><span class="line">    # tf 生成离散型特征需要两个参数,特征名和特征值</span><br><span class="line">    # tf 生成 one-hot 编码:indicator_column</span><br><span class="line">    <span class="builtin-name">print</span>(categorical_column,vocab)</span><br><span class="line">    feature_columns.append(tf.feature_column.indicator_column(</span><br><span class="line">        tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">            categorical_column,vocab)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理连续型特征</span></span><br><span class="line">numeric_columns=[<span class="string">'age'</span>,<span class="string">'fare'</span>]</span><br><span class="line"><span class="keyword">for</span> numeric_column <span class="keyword">in</span> numeric_columns:</span><br><span class="line">    <span class="builtin-name">print</span>(numeric_column)</span><br><span class="line">    feature_columns.append(tf.feature_column.numeric_column(numeric_column,<span class="attribute">dtype</span>=tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'feature_columns:\n'</span>,feature_columns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 制作数据集</span></span><br><span class="line">def make_dataset(data_df,label,<span class="attribute">epochs</span>=10,shuffle=True,batch_size=32):</span><br><span class="line">    <span class="attribute">dataset</span>=tf.data.Dataset.from_tensor_slices(</span><br><span class="line">        (dict(data_df),label))</span><br><span class="line">    <span class="keyword">if</span> shuffle:# 是否打乱数据集</span><br><span class="line">        <span class="attribute">dataset</span>=dataset.shuffle(10000)</span><br><span class="line">    # 设置数据集需要迭代的次数</span><br><span class="line">    <span class="attribute">dataset</span>=dataset.repeat(epochs).batch(batch_size)</span><br><span class="line">    return dataset</span><br><span class="line">	</span><br><span class="line"><span class="attribute">model</span>=keras.models.Sequential([</span><br><span class="line">    keras.layers.DenseFeatures(feature_columns),</span><br><span class="line">    keras.layers.Dense(100,<span class="attribute">activation</span>=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(100,<span class="attribute">activation</span>=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(2,<span class="attribute">activation</span>=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment"># tf2.1.0的版本里如果不单独设置，则默认sdg=0.01，这样收敛太快容易找不到对应的值，所以手动调一下</span></span><br><span class="line"><span class="attribute">sgd</span>=keras.optimizers.SGD(0.001)</span><br><span class="line">model.compile(</span><br><span class="line">    <span class="attribute">loss</span>=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">    <span class="attribute">optimizer</span>=sgd,</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">	</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">train_dataset</span>=make_dataset(train_df,y_train,epochs=100)</span><br><span class="line"><span class="attribute">eval_dataset</span>=make_dataset(eval_df,y_eval,epochs=1,shuffle=False)</span><br><span class="line"></span><br><span class="line"><span class="comment"># steps_per_epoch:训练集中样本数/batch_size</span></span><br><span class="line"><span class="comment"># validation_steps:验证集中样本数/batch_size</span></span><br><span class="line">model.fit(</span><br><span class="line">    train_dataset,</span><br><span class="line">    <span class="attribute">steps_per_epoch</span>=15,</span><br><span class="line">    <span class="attribute">epochs</span>=100)</span><br><span class="line">	</span><br><span class="line"><span class="comment"># 验证模型</span></span><br><span class="line">loss,<span class="attribute">acc</span>=model.evaluate(eval_dataset)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'loss:'</span>,loss)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'acc:'</span>,acc)</span><br></pre></td></tr></table></figure>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>构建可以在模型中进行训练的数据集主要有两种方式:</p>
<ol>
<li>使用 tf.data.experimental.make_csv_dataset 来设置；</li>
<li>使用 tf.data.Dataset.from_tensor_slices，将数据和标签合并为一个元组来创建数据集。</li>
</ol>
<h3 id="numpy数据预处理"><a href="#numpy数据预处理" class="headerlink" title="numpy数据预处理"></a>numpy数据预处理</h3><p>这类数据的类型.npz,需要通过 np,load()函数来进行加载。<br>数据集下载地址：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http<span class="variable">s:</span>//storage.googleapis.<span class="keyword">com</span>/tensorflow/<span class="keyword">tf</span>-keras-datasets/mnist.npz</span><br></pre></td></tr></table></figure></p>
<p>这个可以说是比较简单的处理方式了，和上面csv的区别仅在于要用到np.load函数。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow_datasets as tfds</span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入数据</span></span><br><span class="line"><span class="attribute">dataset</span>=np.load('./dataset/mnist.npz')</span><br><span class="line"><span class="attribute">train_examples</span>=dataset[<span class="string">'x_train'</span>]</span><br><span class="line"><span class="attribute">train_labels</span>=dataset[<span class="string">'y_train'</span>]</span><br><span class="line"><span class="attribute">test_examples</span>=dataset[<span class="string">'x_test'</span>]</span><br><span class="line"><span class="attribute">test_labels</span>=dataset[<span class="string">'y_test'</span>]</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(train_examples.shape)</span><br><span class="line"><span class="builtin-name">print</span>(train_labels.shape)</span><br><span class="line"><span class="builtin-name">print</span>(test_examples.shape)</span><br><span class="line"><span class="builtin-name">print</span>(test_labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 tf.data.Dataset加载numpy数组</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">train_dataset</span>=tf.data.Dataset.from_tensor_slices((train_examples,train_labels))</span><br><span class="line"><span class="attribute">test_dataset</span>=tf.data.Dataset.from_tensor_slices((test_examples,test_labels))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置数据集的epochs和batch_size</span></span><br><span class="line"><span class="attribute">batch_size</span>=32</span><br><span class="line"><span class="attribute">epochs</span>=10</span><br><span class="line"><span class="attribute">shuffle</span>=10000</span><br><span class="line"></span><br><span class="line"><span class="attribute">train_dataset</span>=train_dataset.repeat(epochs).batch(batch_size).shuffle(shuffle)</span><br><span class="line"><span class="attribute">test_dataset</span>=test_dataset.repeat(1).batch(batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型的构建和训练</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">model</span>=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(28,28)),</span><br><span class="line">    tf.keras.layers.Dense(128,<span class="attribute">activation</span>=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.Dense(10,<span class="attribute">activation</span>=<span class="string">'softmax'</span>)# 最后的分类概率</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    <span class="attribute">optimizer</span>=tf.keras.optimizers.RMSprop(),</span><br><span class="line">    <span class="attribute">loss</span>=tf.keras.losses.SparseCategoricalCrossentropy(),</span><br><span class="line">    metrics=[tf.keras.metrics.SparseCategoricalCrossentropy()])</span><br><span class="line">	</span><br><span class="line">model.fit(</span><br><span class="line">    train_dataset,</span><br><span class="line">    <span class="attribute">epochs</span>=10)# 这个训练耗时比较长<span class="built_in">..</span>.</span><br><span class="line">	</span><br><span class="line">model.evaluate(test_dataset)</span><br></pre></td></tr></table></figure></p>
<p>至于pandas数据，上面在方式二中已经写过，不再赘述。</p>
<h3 id="图像数据处理"><a href="#图像数据处理" class="headerlink" title="图像数据处理"></a>图像数据处理</h3><p>讲真，看到这块的时候我心情有点复杂，想当年我入坑NLP的时候信誓旦旦的说这辈子绝对不碰cv相关。<br>鬼知道怎么就半只脚踏入了VQA的坑…行吧，那图像处理也得学。</p>
<p>这里使用的数据集下载地址：<br><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">https:</span>//storage.googleapis.com/download.tensorflow<span class="meta">.org</span>/example_images/flower_photos.tgz</span><br></pre></td></tr></table></figure></p>
<p>以及，对于图像分类的例子，可以直接去Kaggle上看那个10-monkeys的例子。</p>
<p>图像处理这块只针对数据的预处理，后续在CNN搭建的过程中会详细描述如何将数据输入神经网络。</p>
<p>老规矩，首先把数据集下载下来,然后存到所需文件夹下面（以下代码格式以Jupyter模式为例）<br><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"></span><br><span class="line">data_root_orig=<span class="string">'dataset/flower_photos'</span></span><br><span class="line">data_root=pathlib.Path(data_root_orig)</span><br></pre></td></tr></table></figure></p>
<p>pathlib是用来加载路径的，具体用法可参考：<a href="https://docs.python.org/zh-cn/3/library/pathlib.html" target="_blank" rel="noopener">https://docs.python.org/zh-cn/3/library/pathlib.html</a></p>
<p>查看不同类型的花花所在的文件夹:<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">item</span> <span class="keyword">in</span> data_root.iterdir():</span><br><span class="line">    print(<span class="built_in">item</span>)</span><br></pre></td></tr></table></figure></p>
<p>输出结果:<br><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\d</span>aisy</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\d</span>andelion</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\L</span>ICENSE.txt</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\r</span>oses</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\s</span>unflowers</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\t</span>ulips</span><br></pre></td></tr></table></figure></p>
<p>打乱数据操作:<br><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import <span class="built_in">random</span></span><br><span class="line"></span><br><span class="line">all_image_paths=list(data_root.glob(<span class="string">'*/*'</span>))</span><br><span class="line">all_image_paths=[str(<span class="built_in">path</span>) <span class="keyword">for</span> <span class="built_in">path</span> <span class="keyword">in</span> all_image_paths]</span><br><span class="line"><span class="built_in">random</span>.shuffle(all_image_paths) # 打乱顺序</span><br><span class="line"></span><br><span class="line">image_count=<span class="built_in">len</span>(all_image_paths)</span><br><span class="line"><span class="built_in">print</span>(image_count)# 打印出图片数量,共有<span class="number">3670</span>张</span><br></pre></td></tr></table></figure></p>
<p>输出:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3670</span></span><br></pre></td></tr></table></figure></p>
<p>查看all_image_paths中的数据格式:<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(('.\n').join(<span class="name">all_image_paths</span>[:<span class="number">10</span>]))</span><br></pre></td></tr></table></figure></p>
<p>输出结果:<br><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\s</span>unflowers<span class="symbol">\1</span>5266715291_dfa3f1d49f_n.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\d</span>andelion<span class="symbol">\4</span>634716478_1cbcbee7ca.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\d</span>aisy<span class="symbol">\1</span>392946544_115acbb2d9.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\s</span>unflowers<span class="symbol">\6</span>250692311_cb60c85ee9_n.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\r</span>oses<span class="symbol">\3</span>494252600_29f26e3ff0_n.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\d</span>andelion<span class="symbol">\5</span>607256228_2294c201b3.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\t</span>ulips<span class="symbol">\1</span>4027372499_30f934d24f_m.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\d</span>aisy<span class="symbol">\3</span>773181799_5def396456.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\t</span>ulips<span class="symbol">\1</span>6862349256_0a1f91ab53.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\s</span>unflowers<span class="symbol">\1</span>8843967474_9cb552716b.jpg</span><br></pre></td></tr></table></figure></p>
<p>检查图片,在处理之前需要知道图片的内容:<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">attributions = (data_root/<span class="string">"LICENSE.txt"</span>).<span class="built_in">open</span>(encoding=<span class="string">'utf-8'</span>).readlines()[<span class="number">4</span>:] # 这个文件包含了所有图片的说明</span><br><span class="line">attributions = [<span class="built_in">line</span>.<span class="built_in">split</span>(<span class="string">' CC-BY '</span>) <span class="keyword">for</span> <span class="built_in">line</span> in attributions]</span><br><span class="line">attributions = dict(attributions)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x,y in attributions.items():</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line">    <span class="built_in">print</span>(y)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure></p>
<p>输出值如下：<br><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">daisy/<span class="number">7568630428</span>_8cf0fc16ff_n.jpg </span><br><span class="line"> by <span class="keyword">A</span> Guy Taking Pictures - https://www.flickr.com/photos/<span class="number">80901381</span>@N04/<span class="number">7568630428</span>/</span><br></pre></td></tr></table></figure></p>
<p>取出图片并展示：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import IPython.<span class="keyword">display</span> <span class="keyword">as</span> <span class="keyword">display</span></span><br><span class="line"></span><br><span class="line">def caption_image(image_path):</span><br><span class="line">    #print(image_path)</span><br><span class="line">    image_rel = pathlib.Path(image_path).relative_to(data_root)</span><br><span class="line">    <span class="keyword">print</span>(image_rel)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">res</span>=<span class="string">"Image (CC BY 2.0) "</span> + <span class="string">' - '</span>.<span class="keyword">join</span>(attributions[str(image_rel)][:-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">res</span></span><br><span class="line">    except Exception <span class="keyword">as</span> <span class="keyword">e</span>:</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> n in <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">  image_path = random.choice(all_image_paths)</span><br><span class="line">  <span class="keyword">display</span>.<span class="keyword">display</span>(<span class="keyword">display</span>.Image(image_path))</span><br><span class="line">  <span class="keyword">print</span>(caption_image(image_path))</span><br><span class="line">  <span class="keyword">print</span>()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/28/JhfbUe.png" alt></p>
<p>众所周知，一个数据集由x和label组成，在这组花类别数据集中，label就是花的类别，每种不同类别的花被单独放在不同的文件夹里面。<br>现在把这些label取出来进行排序并编号。<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">label_names=sorted(<span class="name">item</span>.name for item in data_root.glob('*/') if item.is_dir())</span><br><span class="line">print(<span class="name">label_names</span>)</span><br></pre></td></tr></table></figure></p>
<p>输出值如下：<br><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">'daisy</span>', <span class="symbol">'dandelion</span>', <span class="symbol">'roses</span>', <span class="symbol">'sunflowers</span>', <span class="symbol">'tulips</span>']</span><br></pre></td></tr></table></figure></p>
<p>为每个标签分配索引值（即编号）：<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">label_to_index=dict((<span class="name">name</span>,index) for index,name in enumerate(<span class="name">label_names</span>))</span><br><span class="line">print(<span class="name">label_to_index</span>)</span><br></pre></td></tr></table></figure></p>
<p>输出值如下：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#123;'daisy':</span> <span class="number">0</span><span class="string">,</span> <span class="attr">'dandelion':</span> <span class="number">1</span><span class="string">,</span> <span class="attr">'roses':</span> <span class="number">2</span><span class="string">,</span> <span class="attr">'sunflowers':</span> <span class="number">3</span><span class="string">,</span> <span class="attr">'tulips':</span> <span class="number">4</span><span class="string">&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>完成label的创建，需要把label对应给不同的图片构成一个相应的标签集合。<br>注意：这里的数据是先前已经打乱过的。<br><figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">all_image_labels=[label_to_index[pathlib.<span class="built_in">Path</span>(<span class="built_in">path</span>).parent.name] # 取出当前图片的父级目录</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">path</span> <span class="keyword">in</span> all_image_paths]</span><br><span class="line"><span class="built_in">print</span>(all_image_labels)</span><br><span class="line"><span class="built_in">print</span>(len(all_image_labels))</span><br></pre></td></tr></table></figure></p>
<p>所以现在的图片和label就是一一对应的。<br><img src="https://s1.ax1x.com/2020/04/28/JhhmrV.png" alt></p>
<p>完成x和label的整理，现在需要将这些数据处理为tf模型可以训练的形式。<br>这就需要一个函数 <b> tf.io.read_file </b>.<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取出一条单独的数据作示范</span></span><br><span class="line"><span class="attribute">img_path</span>=all_image_paths[0]</span><br><span class="line"><span class="attribute">img_raw</span>=tf.io.read_file(img_path)</span><br><span class="line"><span class="builtin-name">print</span>(repr(img_raw)[:100])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/28/Jhh82R.png" alt></p>
<p>在此基础上将图片解码为图像tensor:<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img_tensor=tf<span class="selector-class">.image</span>.decode_image(img_raw)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(img_tensor.shape)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(img_tensor.dtype)</span></span></span><br></pre></td></tr></table></figure></p>
<p>输出值如下：<br><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">259</span>, <span class="number">320</span>, <span class="number">3</span>)</span><br><span class="line">&lt;d<span class="keyword">type</span>: 'uint8'&gt;</span><br></pre></td></tr></table></figure></p>
<p>从上面的输出中可以看出，每张图片的大小是不一致的，但是模型需要大小一致的矩阵合集作为输入，所以需要人工调节图片大小。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据模型调整输入大小</span></span><br><span class="line"><span class="attribute">img_final</span>=tf.image.resize(img_tensor,[192,192])</span><br><span class="line"><span class="comment"># 对每个像素进行处理</span></span><br><span class="line"><span class="attribute">img_final</span>=img_final/255.0</span><br><span class="line"><span class="builtin-name">print</span>(img_final.shape)</span><br><span class="line"><span class="builtin-name">print</span>(img_final.numpy().min())</span><br><span class="line"><span class="builtin-name">print</span>(img_final.numpy().max())</span><br></pre></td></tr></table></figure></p>
<p>输出结果：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">192</span>, <span class="number">192</span>, <span class="number">3</span>)</span><br><span class="line"><span class="number">0.0</span></span><br><span class="line"><span class="number">0.98491627</span></span><br></pre></td></tr></table></figure></p>
<p>为了方便处理每张图片时不需要重复写代码，可以将上述操作封装为函数。<br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 处理图像</span><br><span class="line"><span class="function">def <span class="title">preprocess_image</span><span class="params">(<span class="built_in">image</span>)</span>:</span></span><br><span class="line"><span class="function">    <span class="built_in">image</span></span>=tf.<span class="built_in">image</span>.decode_jpeg(<span class="built_in">image</span>,channels=<span class="number">3</span>)</span><br><span class="line">    <span class="built_in">image</span>=tf.<span class="built_in">image</span>.resize(<span class="built_in">image</span>,[<span class="number">192</span>,<span class="number">192</span>])</span><br><span class="line">    <span class="built_in">image</span>/=<span class="number">255.0</span> # 将数值归一化在 [<span class="number">0</span>,<span class="number">1</span>]区间</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">image</span></span><br><span class="line">	</span><br><span class="line"># 加载并处理图像</span><br><span class="line">def load_and_preprocess_image(path):</span><br><span class="line">    <span class="built_in">image</span>=tf.io.read_file(path)</span><br><span class="line">    <span class="keyword">return</span> preprocess_image(<span class="built_in">image</span>)</span><br></pre></td></tr></table></figure></p>
<p>OK，正式开始调用 <b>tf.data.Dataset.from_tensor_slices</b> 构造数据集。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">path_ds</span>=tf.data.Dataset.from_tensor_slices(all_image_paths)</span><br><span class="line"><span class="builtin-name">print</span>(path_ds)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个新的数据集,通过在路径数据集上映射preprocess_image来动态加载和格式化图片</span></span><br><span class="line"><span class="attribute">AUTOTUNE</span>=tf.data.experimental.AUTOTUNE</span><br><span class="line"><span class="comment"># 数据块</span></span><br><span class="line"><span class="attribute">image_ds</span>=path_ds.map(load_and_preprocess_image,num_parallel_calls=AUTOTUNE)</span><br><span class="line"><span class="comment"># 标签块</span></span><br><span class="line"><span class="attribute">label_ds</span>=tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels,tf.int64))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试取出的labels</span></span><br><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> label_ds.take(10):</span><br><span class="line">    <span class="builtin-name">print</span>(label_names[label.numpy()])</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/04/28/Jh4lef.png" alt></p>
<p>对数据集进行打包（对x和label进行concate），tf框架提供了两种打包方式：</p>
<ol>
<li><b>tf.data.Dataset.zip</b><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_label_ds=tf<span class="selector-class">.data</span><span class="selector-class">.Dataset</span>.zip((image_ds,label_ds))</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(image_label_ds)</span></span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><img src="https://s1.ax1x.com/2020/04/28/Jh4ayq.png" alt></p>
<ol start="2">
<li><b>tf.data.Dataset.from_tensor_slices</b><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ds</span>=tf.data.Dataset.from_tensor_slices((all_image_paths,all_image_labels))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 元组被解压缩到映射函数的位置参数中</span></span><br><span class="line">def load_and_preprocess_from_path_label(path,label):</span><br><span class="line">    return load_and_preprocess_image(path),label</span><br><span class="line"></span><br><span class="line"><span class="attribute">image_label_ds</span>=ds.map(load_and_preprocess_from_path_label)</span><br><span class="line"><span class="builtin-name">print</span>(image_label_ds)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><img src="https://s1.ax1x.com/2020/04/28/Jh46fJ.png" alt></p>
<p>至此，完成数据集制作只需要设置完数据的batch_size,epochs，shuffle等参数即可。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">batch_size</span>=32</span><br><span class="line"><span class="attribute">shuffle_size</span>=3670</span><br><span class="line"><span class="attribute">epochs</span>=10</span><br><span class="line"><span class="comment"># 设置一个和数据集大小一致的shuffle buffer size来保证数据被充分打乱</span></span><br><span class="line"><span class="comment"># 另外,如果buffer_size设置过大，会引起延迟</span></span><br><span class="line"><span class="attribute">ds</span>=image_label_ds.shuffle(shuffle_size)</span><br><span class="line"><span class="comment"># 注意:先repeat再batch</span></span><br><span class="line"><span class="attribute">ds</span>=ds.repeat(epochs).batch(batch_size)</span><br><span class="line"><span class="builtin-name">print</span>(ds)</span><br></pre></td></tr></table></figure></p>
<p>图片数据处理部分结束。</p>
<h3 id="文本数据处理"><a href="#文本数据处理" class="headerlink" title="文本数据处理"></a>文本数据处理</h3><p>这块内容不使用官网提供的数据集，使用keras下面的imdb数据集。<br>处理文本数据主要包含三个步骤：</p>
<ol>
<li>生成词语及其序号对应的dict，正向和反向各一份；</li>
<li>将所有的文本处理成长度相同的向量,tf2.0提供了 <b> tf.keras.preprocessing.pad_sequences </b> 来完成填充。</li>
</ol>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">tf</span>.keras.preprocessing.sequence.pad_sequences 参数说明：</span><br><span class="line">paramter1:需要进行处理的数据,这里直接输入 train_data,数据类型是<span class="keyword">list</span></span><br><span class="line">value:需要填充的值,害,那<span class="symbol">&lt;PAD&gt;</span>填呗</span><br><span class="line">paddin<span class="variable">g:</span>此处可以填两个值,post和<span class="keyword">pre</span>,区别在于post在于把值填充在<span class="keyword">list</span>后面,<span class="keyword">pre</span>在于把值填充在<span class="keyword">list</span>前面</span><br><span class="line">maxlen:填充后的最大长度</span><br></pre></td></tr></table></figure>
<p>3.构造embedding层,embedding层的主要作用：<br>(1) 定义一个大小为 (vocab_size,embedding_dim) 的矩阵；<br>(2) 对于任意一个样本,例如[1,2,3,4,…]，将每个样本中的单词按序号从里面取出对应的值,将每个样本变为大小为 (max_length,embedding_dim) 的矩阵，这里的max_length指输入句子设置的最大长度；<br>(3) 在训练时，输入就变成 (batch_size,max_length,embedding_dim).</p>
<p>完整版代码如下：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"><span class="keyword">from</span> tensorflow import keras</span><br><span class="line">import os</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">'HTTP_PROXY'</span>]=<span class="string">'127.0.0.1:1080'</span></span><br><span class="line">os.environ[<span class="string">'HTTPS_PROXY'</span>]=<span class="string">'127.0.0.1:1080'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据集</span></span><br><span class="line"><span class="attribute">imdb</span>=keras.datasets.imdb</span><br><span class="line"><span class="comment"># 设置词表大小,后面构建模型时需要制作Embedding layer</span></span><br><span class="line"><span class="attribute">vocab_size</span>=10000</span><br><span class="line"><span class="comment"># 空出三个字符作为填充数据</span></span><br><span class="line"><span class="attribute">index_from</span>=3</span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">(train_data,train_labels),(test_data,test_labels)=imdb.load_data(</span><br><span class="line">    <span class="attribute">num_words</span>=vocab_size,index_from=index_from)</span><br><span class="line">	</span><br><span class="line"><span class="builtin-name">print</span>(train_data[0],train_labels[0])</span><br><span class="line"><span class="builtin-name">print</span>(train_data.shape,train_labels.shape)</span><br><span class="line"><span class="builtin-name">print</span>(len(train_data[0]))</span><br><span class="line"><span class="builtin-name">print</span>(len(train_data[1]))</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(test_data.shape,test_labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取词在词表中的词序</span></span><br><span class="line"><span class="attribute">word_index</span>=imdb.get_word_index() # 取出来的值是dict类型</span><br><span class="line"><span class="comment"># 查看词表的长度</span></span><br><span class="line"><span class="builtin-name">print</span>(word_index)</span><br><span class="line"><span class="builtin-name">print</span>()</span><br><span class="line"><span class="builtin-name">print</span>(len(word_index))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对词序列表设置偏移</span></span><br><span class="line">word_index=&#123;k:(v+3) <span class="keyword">for</span> k,v <span class="keyword">in</span> word_index.items()&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对偏移后的词表进行补位</span></span><br><span class="line">word_index[<span class="string">'&lt;PAD&gt;'</span>]=0</span><br><span class="line">word_index[<span class="string">'&lt;START&gt;'</span>]=1</span><br><span class="line">word_index[<span class="string">'&lt;UNK&gt;'</span>]=2</span><br><span class="line">word_index[<span class="string">'&lt;END&gt;'</span>]=3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成反向词表</span></span><br><span class="line"><span class="attribute">reverse_word_index</span>=dict([(value,key) <span class="keyword">for</span> key,value <span class="keyword">in</span> word_index.items()])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练数据原始的文本信息</span></span><br><span class="line">def decode_review(text_ids):</span><br><span class="line">    return <span class="string">' '</span>.join([reverse_word_index.<span class="builtin-name">get</span>(word_id,<span class="string">'&lt;UNK&gt;'</span>) <span class="keyword">for</span> word_id <span class="keyword">in</span> text_ids])</span><br><span class="line"></span><br><span class="line">decode_review(train_data[0])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对数据进行预处理</span></span><br><span class="line"><span class="comment"># 补齐文本长度，对于长度小于或者大于500的文本，统一将文本补齐成大小是500的向量</span></span><br><span class="line"><span class="attribute">max_length</span>=500</span><br><span class="line"><span class="comment"># 处理训练集</span></span><br><span class="line"><span class="attribute">train_data</span>=keras.preprocessing.sequence.pad_sequences(</span><br><span class="line">    train_data,</span><br><span class="line">    <span class="attribute">value</span>=word_index[<span class="string">'&lt;PAD&gt;'</span>],</span><br><span class="line">    <span class="attribute">padding</span>=<span class="string">'post'</span>,</span><br><span class="line">    <span class="attribute">maxlen</span>=max_length)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对训练集的代码复制粘贴并修改得到测试集（逃</span></span><br><span class="line"><span class="attribute">test_data</span>=keras.preprocessing.sequence.pad_sequences(</span><br><span class="line">    test_data,</span><br><span class="line">    <span class="attribute">value</span>=word_index[<span class="string">'&lt;PAD&gt;'</span>],</span><br><span class="line">    <span class="attribute">padding</span>=<span class="string">'post'</span>,</span><br><span class="line">    <span class="attribute">maxlen</span>=max_length)</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(train_data[0])</span><br><span class="line"><span class="builtin-name">print</span>(len(train_data[0]))</span><br><span class="line"><span class="builtin-name">print</span>(train_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建Embedding层和模型</span></span><br><span class="line"><span class="comment"># 将每个单词映射成维度为16的向量</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">embedding_dim</span>=16</span><br><span class="line"><span class="attribute">batch_size</span>=128</span><br><span class="line"></span><br><span class="line"><span class="attribute">model</span>=keras.models.Sequential([</span><br><span class="line">    keras.layers.Embedding(</span><br><span class="line">        vocab_size,</span><br><span class="line">        embedding_dim,</span><br><span class="line">        <span class="attribute">input_length</span>=max_length),</span><br><span class="line">    # batch_size x max_length x embedding_dim -&gt; batch_size x embedding_dim</span><br><span class="line">    # 消去max_length这个维度</span><br><span class="line">    keras.layers.SimpleRNN(</span><br><span class="line">        <span class="attribute">units</span>=64,</span><br><span class="line">        <span class="attribute">return_sequences</span>=<span class="literal">False</span>),</span><br><span class="line">    keras.layers.Dense(64,<span class="attribute">activation</span>=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(1,<span class="attribute">activation</span>=<span class="string">'sigmoid'</span>) # 最后的输出只有一种结果</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    <span class="attribute">optimizer</span>=<span class="string">'adam'</span>,</span><br><span class="line">    <span class="attribute">loss</span>=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">	</span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"><span class="comment"># 这个数据集本身没有设置验证集，所以将训练集中20%的数据划出来作为验证集</span></span><br><span class="line">model.fit(</span><br><span class="line">    train_data,</span><br><span class="line">    train_labels,</span><br><span class="line">    <span class="attribute">epochs</span>=30,</span><br><span class="line">    <span class="attribute">batch_size</span>=batch_size,</span><br><span class="line">    <span class="attribute">validation_split</span>=0.2)</span><br><span class="line">	</span><br><span class="line"><span class="comment"># 验证数据</span></span><br><span class="line">loss,<span class="attribute">accuracy</span>=model.evaluate(test_data,test_labels,batch_size=batch_size)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'loss:'</span>,loss)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'accuracy:'</span>,accuracy)</span><br></pre></td></tr></table></figure></p>
<h2 id="Estimator"><a href="#Estimator" class="headerlink" title="Estimator"></a>Estimator</h2><p>Estimator 是 Tensorflow 完整模型的高级表示，它被设计用于轻松扩展和异步训练。<br>这个章节主要讲两个部分：<br>1.预创建的Estimator;<br>2.将Keras模型转换为Estimator模型.</p>
<h3 id="预创建的Estimator"><a href="#预创建的Estimator" class="headerlink" title="预创建的Estimator"></a>预创建的Estimator</h3><p>这里以Estimator解决鸢尾花分类问题为例，数据集地址：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">训练集：<span class="string">https:</span><span class="comment">//storage.googleapis.com/download.tensorflow.org/data/iris_training.csv</span></span><br><span class="line">测试集：<span class="string">https:</span><span class="comment">//storage.googleapis.com/download.tensorflow.org/data/iris_test.csv</span></span><br></pre></td></tr></table></figure></p>
<p>要基于一个数据集建立模型，首先需要对这个数据集的格式进行了解。<br>数据集有五列，包含了花萼长度（SepalLength），花萼宽度（SepalWidth），花瓣长度（PetalLength），花瓣宽度（PetalWidth）四个特征值数列和一个标签列（Species）。花的种类又包括 Setosa，Versicolor，Virginica 三种类别，数据集中已经处理为0,1,2三个标签。</p>
<p><b>加载运行环境并设置需要更新的列名称和种类名称<b><br><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">csv_column_names=[<span class="string">'SepalLength'</span>, <span class="string">'SepalWidth'</span>, <span class="string">'PetalLength'</span>, <span class="string">'PetalWidth'</span>, <span class="string">'Species'</span>]</span><br><span class="line">species=[<span class="string">'Setosa'</span>, <span class="string">'Versicolor'</span>, <span class="string">'Virginica'</span>]</span><br></pre></td></tr></table></figure></b></b></p>
<p><b>读取文件并更新列名</b><br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">train</span>=pd.read_csv('../dataset/iris_training.csv',</span><br><span class="line">    <span class="attribute">names</span>=csv_column_names,header=0) # 设置header为0,取消原先的列名</span><br><span class="line"><span class="attribute">test</span>=pd.read_csv('../dataset/iris_test.csv',</span><br><span class="line">    <span class="attribute">names</span>=csv_column_names,header=0)</span><br><span class="line"><span class="builtin-name">print</span>(train.head())</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/29/JoDZQK.png" alt></p>
<p><b>分别取出训练集和测试集的label</b><br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">train_y</span>=train.pop('Species')</span><br><span class="line"><span class="attribute">test_y</span>=test.pop('Species')</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(train.head())</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/29/JoDDWq.png" alt></p>
<p>数据集读取完毕，下面要通过Estimator来定义模型。Estimator要求完成以下工作（这段摘自官网）：<br>(1) 创建一个或多个输入函数；<br>(2) 定义模型的特征列；<br>(3) 实例化一个Estimator，指定特征列和各种超参数；<br>(4) 在Estimator对象上调用一个或多个方法，传递合适的输入函数以作为数据源.</p>
<p><b>创建输入函数</b><br>输入函数是一个返回tf.data.Dataset对象的函数，此对象会输出下列两个元素的元组：<br>(1) feature:通过Python字典构建，键作为特征名称，值作为包含此特征所有值的数组;<br>(2) label：包含每个样本标签的数值.<br>e.g.<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def input_evaluation_set():</span><br><span class="line">    <span class="built_in">features</span> = &#123;'SepalLength': <span class="built_in">np</span>.<span class="built_in">array</span>([<span class="number">6.4</span>, <span class="number">5.0</span>]),</span><br><span class="line">                'SepalWidth':  <span class="built_in">np</span>.<span class="built_in">array</span>([<span class="number">2.8</span>, <span class="number">2.3</span>]),</span><br><span class="line">                'PetalLength': <span class="built_in">np</span>.<span class="built_in">array</span>([<span class="number">5.6</span>, <span class="number">3.3</span>]),</span><br><span class="line">                'PetalWidth':  <span class="built_in">np</span>.<span class="built_in">array</span>([<span class="number">2.2</span>, <span class="number">1.0</span>])&#125;</span><br><span class="line">    <span class="built_in">labels</span> = <span class="built_in">np</span>.<span class="built_in">array</span>([<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">    <span class="built_in">return</span> <span class="built_in">features</span>, <span class="built_in">labels</span></span><br></pre></td></tr></table></figure></p>
<p>输入函数可以自定义，不过官方的建议是使用tf的DataSet API，这个API可以解析各种类型的数据。使用Dataset API，可以轻松地从大量文件中并行读取记录，并将它们合并为单个数据流。</p>
<p>简化示例，以pandas加载数据，并利用此内存数据构建输入管道。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def input_fn(features,labels,<span class="attribute">training</span>=<span class="literal">True</span>,batch_size=256):</span><br><span class="line">    # 将输入转换为数据集</span><br><span class="line">    <span class="attribute">dataset</span>=tf.data.Dataset.from_tensor_slices((dict(features),labels))</span><br><span class="line">    # 在训练的条件下对数据进行shuffle</span><br><span class="line">    <span class="keyword">if</span> training:</span><br><span class="line">        <span class="attribute">dataset</span>=dataset.shuffle(1000).repeat()</span><br><span class="line">    return dataset.batch(batch_size)</span><br></pre></td></tr></table></figure></p>
<p><b>定义特征列</b></p>
<p>特征列是一个对象，用于描述模型应该如何使用特征字典中的原始输入数据。构建Estimator模型时需要传递一个特征列表，包含模型需要使用的每个特征。<br>主要函数：tf.feature_column</p>
<p>对于鸢尾花的分类问题，四个原始特征都是数值，基于这些数值构建特征列表。<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">my_feature_columns=[]</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">key</span> <span class="keyword">in</span> train.keys():</span><br><span class="line">    my_feature_columns.<span class="built_in">append</span>(tf.feature_column.numeric_column(<span class="built_in">key</span>=<span class="built_in">key</span>))</span><br><span class="line"><span class="built_in">print</span>(my_feature_columns)</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/29/JTSXQA.png" alt></p>
<p><b>实例化Estimator</b></p>
<p>TF框架中提供了几个已经预创建的Estimator分类器，其中包括：<br>(1) tf.estimator.DNNClassifier 用于多类别分类的深度模型;<br>(2) tf.estimator.DNNLinearCombinedClassifier 用于广度与深度模型;<br>(3) tf.estimator.LinearClassifier 用于基于线性模型的分类器.</p>
<p>这里以tf.estimator.DNNClassifier为例。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置保存模型的目录</span></span><br><span class="line"><span class="attribute">output_dir</span>=<span class="string">'DNNClassifier'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">    os.makedirs(output_dir)</span><br><span class="line"><span class="attribute">classifier</span>=tf.estimator.DNNClassifier(</span><br><span class="line">    <span class="attribute">feature_columns</span>=my_feature_columns,</span><br><span class="line">    <span class="attribute">model_dir</span>=output_dir,</span><br><span class="line">    # 隐藏层中神经元的个数</span><br><span class="line">    hidden_units=[30,10],</span><br><span class="line">    # 模型必须从三个类别中选择</span><br><span class="line">    <span class="attribute">n_classes</span>=3)</span><br></pre></td></tr></table></figure></p>
<p><b>训练模型</b></p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">classifier.train(</span><br><span class="line">    # 注意:input_fn调用封装在lambda中以获取参数</span><br><span class="line">    <span class="attribute">input_fn</span>=lambda: input_fn(train,train_y,<span class="attribute">training</span>=<span class="literal">True</span>),</span><br><span class="line">    <span class="attribute">steps</span>=10000)</span><br></pre></td></tr></table></figure>
<p><b>测试模型</b><br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">eval_result = classifier.evaluate(</span><br><span class="line">    <span class="attribute">input_fn</span>=lambda: input_fn(test, test_y, <span class="attribute">training</span>=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'\nTest set accuracy: &#123;accuracy:0.3f&#125;\n'</span>.format(*<span class="number">*e</span>val_result))</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/29/JTvJte.png" alt></p>
<h3 id="Keras模型转Estimator"><a href="#Keras模型转Estimator" class="headerlink" title="Keras模型转Estimator"></a>Keras模型转Estimator</h3><p>这里以泰坦尼克号生存概率文件做预测，数据集下载地址:<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">http<span class="variable">s:</span>//storage.googleapis.<span class="keyword">com</span>/<span class="keyword">tf</span>-datasets/titanic/train.csv</span><br><span class="line">http<span class="variable">s:</span>//storage.googleapis.<span class="keyword">com</span>/<span class="keyword">tf</span>-datasets/titanic/<span class="built_in">eval</span>.csv</span><br></pre></td></tr></table></figure></p>
<p>转换的步骤主要用到的模型是 tf.keras.estimator.model_to_estimator</p>
<p><b>加载环境</b><br><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br><span class="line"><span class="title">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure></p>
<p><b>建立一个Keras模型</b><br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">model</span>=keras.models.Sequential([</span><br><span class="line">    keras.layers.Dense(16,<span class="attribute">activation</span>=<span class="string">'relu'</span>,input_shape=(4,)),</span><br><span class="line">    keras.layers.Dropout(0.2),</span><br><span class="line">    keras.layers.Dense(3)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    <span class="attribute">loss</span>=keras.losses.SparseCategoricalCrossentropy(from_logits=True),</span><br><span class="line">    <span class="attribute">optimizer</span>=<span class="string">'adam'</span>)</span><br><span class="line">	</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/29/JHih5t.png" alt></p>
<p><b>定义输入函数</b></p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def input_fn():</span><br><span class="line">    <span class="built_in">split</span>=tfds.Split.TRAIN</span><br><span class="line">    dataset=tfds.<span class="built_in">load</span>('iris',<span class="built_in">split</span>=<span class="built_in">split</span>,as_supervised=True)</span><br><span class="line">    dataset=dataset.<span class="built_in">map</span>(<span class="built_in">lambda</span> <span class="built_in">features</span>,<span class="built_in">labels</span>:(&#123;'dense_input':<span class="built_in">features</span>&#125;,<span class="built_in">labels</span>))</span><br><span class="line">    dataset=dataset.<span class="built_in">batch</span>(<span class="number">32</span>).repeat()</span><br><span class="line">    <span class="built_in">return</span> dataset</span><br></pre></td></tr></table></figure>
<p><b>为Keras模型创建一个Estimator</b></p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">model_dir</span>=<span class="string">'keras_to_estimator'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(model_dir):</span><br><span class="line">    os.mkdir(model_dir)</span><br><span class="line"><span class="attribute">keras_estimator</span>=keras.estimator.model_to_estimator(</span><br><span class="line">    <span class="attribute">keras_model</span>=model,</span><br><span class="line">    <span class="attribute">model_dir</span>=model_dir)</span><br></pre></td></tr></table></figure>
<p><b>训练模型</b></p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras_estimator.train<span class="params">(<span class="attr">input_fn</span>=input_fn,<span class="attr">steps</span>=5000)</span></span><br></pre></td></tr></table></figure>
<p><b>测试模型</b></p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">eval_result</span>=keras_estimator.evaluate(input_fn=input_fn,steps=10)</span><br><span class="line"><span class="builtin-name">print</span>(eval_result)</span><br></pre></td></tr></table></figure>
<p>输出结果是：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#123;'loss':</span> <span class="number">0.061623283</span><span class="string">,</span> <span class="attr">'global_step':</span> <span class="number">5000</span><span class="string">&#125;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="自定义"><a href="#自定义" class="headerlink" title="自定义"></a>自定义</h2><p>害，我觉得这块真的需要重视，因为复现别人的论文，可能又是公式又是自定义层什么的。</p>
<h3 id="张量和操作"><a href="#张量和操作" class="headerlink" title="张量和操作"></a>张量和操作</h3><p>一个张量是一个多维度的数组，类似于numpy创建的ndarray。tf.Tensor对象的参数包括一个数据类型和一个数据大小。<br>除此之外，tf.Tensor可以保存在加速器（GPU）内存中，TensorFlow提供了丰富的操作库(tf.add，tf.matmul等)。</p>
<p>这个部分，先加载一下环境，Jupyter真香。<br><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure></p>
<h4 id="张量的基本计算"><a href="#张量的基本计算" class="headerlink" title="张量的基本计算"></a>张量的基本计算</h4><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="name">tf</span>.add(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">print(<span class="name">tf</span>.add([<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]))</span><br><span class="line">print(<span class="name">tf</span>.square(<span class="number">5</span>))</span><br><span class="line">print(<span class="name">tf</span>.reduce_sum([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]))</span><br><span class="line"></span><br><span class="line">print(<span class="name">tf</span>.square(<span class="number">2</span>)+tf.square(<span class="number">3</span>))</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/04/30/JqZ4Gd.png" alt></p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x=tf.matmul(<span class="string">[[1]]</span>,<span class="string">[[2,3]]</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="built_in">print</span>(x.dtype)</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/04/30/JqZxRs.png" alt></p>
<h4 id="Numpy和Tensor的相互转换"><a href="#Numpy和Tensor的相互转换" class="headerlink" title="Numpy和Tensor的相互转换"></a>Numpy和Tensor的相互转换</h4><p>将tensor转换为numpy的ndarrays只需要使用一个工具，在tensor后面加上.numpy()即可。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="attribute">ndarray</span>=np.ones([3,3])</span><br><span class="line"><span class="comment"># 经过tensor操作可以把numpy数组转换为tensor</span></span><br><span class="line"><span class="attribute">tensor</span>=tf.multiply(ndarray,42)</span><br><span class="line"><span class="builtin-name">print</span>(tensor)</span><br><span class="line"><span class="builtin-name">print</span>()</span><br><span class="line"><span class="comment"># 经过numpy计算把tensor转换为numpy数组</span></span><br><span class="line"><span class="builtin-name">print</span>(np.<span class="builtin-name">add</span>(tensor,1))</span><br><span class="line"><span class="builtin-name">print</span>()</span><br><span class="line"><span class="comment"># 把tensor取出作为numpy数组</span></span><br><span class="line"><span class="builtin-name">print</span>(tensor.numpy())</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/30/Jqn4G4.png" alt></p>
<h4 id="设置运行设备"><a href="#设置运行设备" class="headerlink" title="设置运行设备"></a>设置运行设备</h4><p>with tf.device()，然后指定设备，本机运行设置为CPU:0，GPU设置为 GPU:0。</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import <span class="built_in">time</span></span><br><span class="line"></span><br><span class="line">def time_matmul(x):</span><br><span class="line">    <span class="built_in">start</span>=<span class="built_in">time</span>.<span class="built_in">time</span>()</span><br><span class="line">    <span class="keyword">for</span> loop <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        tf.matmul(x,x)</span><br><span class="line">    <span class="built_in">result</span>=<span class="built_in">time</span>.<span class="built_in">time</span>()-<span class="built_in">start</span></span><br><span class="line">    print(<span class="string">"10 loops:&#123;:0.2f&#125;ms"</span>.<span class="built_in">format</span>(<span class="number">1000</span>*<span class="built_in">result</span>))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'On CPU:'</span>)</span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'CPU:0'</span>):</span><br><span class="line">    x=tf.<span class="built_in">random</span>.uniform([<span class="number">1000</span>,<span class="number">1000</span>])</span><br><span class="line">    assert x.device.endswith(<span class="string">'CPU:0'</span>)</span><br><span class="line">    time_matmul(x)</span><br></pre></td></tr></table></figure>
<p>GPU加速这块…我没有GPU…就跳过吧…跳过吧…</p>
<h3 id="自定义层"><a href="#自定义层" class="headerlink" title="自定义层"></a>自定义层</h3><p>tf2.0把神经网络层都封装在keras.layers下面：</p>
<ol>
<li>全连接层使用 keras.layers.Dense，里面的参数一般包括：全连接神经元的个数（必写），输入大小（可以省略）。</li>
<li>RNN层：keras.layers.SimpleRNN;</li>
<li>CNN层：keras.layers.Conv2D.</li>
</ol>
<h2 id="卷积神经网络实现"><a href="#卷积神经网络实现" class="headerlink" title="卷积神经网络实现"></a>卷积神经网络实现</h2><p>这块其实我比较纠结，如果在这写CNN的话，那这个篇幅可能会有点长，我纠结了大概五秒钟，突然想起来以前看过一篇写得特别好的blog，贴出来吧。<br><a href="http://colah.github.io/posts/2014-07-Conv-Nets-Modular/" target="_blank" rel="noopener">Conv Nets: A Modular Perspective</a><br>作者大大的很多文章都写得特别好，强推。</p>
<p>CNN这块我准备安排两个例子来讲，图像分类和文本分类。</p>
<h3 id="CNN实现图像分类"><a href="#CNN实现图像分类" class="headerlink" title="CNN实现图像分类"></a>CNN实现图像分类</h3><p>步骤：<br>1.加载图像数据集；<br>2.数据集预处理(归一化，图像大小调整等)；<br>3.搭建CNN模型（卷积层+池化层+Flatten+全连接层*2）；<br>4.训练模型；<br>5.测试模型.</p>
<p><b>加载运行环境</b><br><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="title">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="title">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br></pre></td></tr></table></figure></p>
<p><b>加载数据集</b></p>
<p>这里使用tf自带的fashion_mnist数据集<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fashion_mnist=keras<span class="selector-class">.datasets</span>.fashion_mnist</span><br><span class="line">(x_train_all,y_train_all),(x_test,y_test)=fashion_mnist.load_data()</span><br><span class="line">x_valid,x_train=x_train_all[:<span class="number">5000</span>],x_train_all[<span class="number">5000</span>:]</span><br><span class="line">y_valid, y_train = y_train_all[:<span class="number">5000</span>], y_train_all[<span class="number">5000</span>:]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(x_valid.shape, y_valid.shape)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(x_train.shape, y_train.shape)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(x_test.shape, y_test.shape)</span></span></span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/30/Jq4go9.png" alt></p>
<p><b>图像数据预处理</b></p>
<p>这里需要对图像的像素进行归一化处理，但是归一化只能处理二维矩阵，训练数据的输入大小是[None,28,28]，所以训练数据需要转化为[None,784]。<br>原图像大小：[28,28]，黑白图像，单通道，over。<br><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">scaler</span>=<span class="type">StandardScaler</span>()</span><br><span class="line"><span class="title">x_train_scaled</span>=scaler.fit_transform(</span><br><span class="line">    x_train.<span class="keyword">as</span><span class="keyword">type</span>(np.float32).reshape(-1,1)).reshape(-1,28,28,1)</span><br><span class="line"><span class="title">x_valid_scaled</span>=scaler.fit_transform(</span><br><span class="line">    x_valid.<span class="keyword">as</span><span class="keyword">type</span>(np.float32).reshape(-1,1)).reshape(-1,28,28,1)</span><br><span class="line"><span class="title">x_test_scaled</span>=scaler.fit_transform(</span><br><span class="line">    x_test.<span class="keyword">as</span><span class="keyword">type</span>(np.float32).reshape(-1,1)).reshape(-1,28,28,1)</span><br></pre></td></tr></table></figure></p>
<p><b>搭建CNN模型</b></p>
<p>CNN模型=卷积层+池化层+全连接层+输出层，over。<br>其中，卷积层和池化层可以有多个。</p>
<p>第一层卷积层需要设置 input_shape，通常是图片大小 (width,height,channels)。<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">model=keras.models.Sequential()</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">卷积层参数说明:</span></span><br><span class="line"><span class="string">filters:有多少个卷积核</span></span><br><span class="line"><span class="string">kernel_size:卷积核大小</span></span><br><span class="line"><span class="string">padding:是否让输入和输出保持一致</span></span><br><span class="line"><span class="string">activation:激活函数</span></span><br><span class="line"><span class="string">input_shape:设置输入大小</span></span><br><span class="line"><span class="string">''</span>'</span><br><span class="line">model.add(keras.layers.Conv2D(</span><br><span class="line">    <span class="attr">filters=32,</span></span><br><span class="line">    <span class="comment"># kernel_size:3 x 3</span></span><br><span class="line">    <span class="attr">kernel_size=3,</span></span><br><span class="line">    <span class="attr">activation='selu',</span></span><br><span class="line">    <span class="attr">padding='same',</span></span><br><span class="line">    <span class="attr">input_shape=(28,28,1)))</span></span><br><span class="line">model.add(keras.layers.Conv2D(</span><br><span class="line">    <span class="attr">filters=32,</span></span><br><span class="line">    <span class="attr">kernel_size=3,</span></span><br><span class="line">    <span class="attr">padding='same',</span></span><br><span class="line">    <span class="attr">activation='selu'))</span></span><br><span class="line"><span class="comment"># 设置池化层</span></span><br><span class="line"><span class="comment"># pool_size:池化窗口大小</span></span><br><span class="line">model.add(keras.layers.MaxPool2D(<span class="attr">pool_size=2))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 上述内容再来一遍</span></span><br><span class="line"><span class="comment"># 为了缓解信息损失,这里需要将filters翻倍</span></span><br><span class="line">model.add(keras.layers.Conv2D(</span><br><span class="line">    <span class="attr">filters=64,</span></span><br><span class="line">    <span class="attr">kernel_size=3,</span></span><br><span class="line">    <span class="attr">activation='selu',</span></span><br><span class="line">    <span class="attr">padding='same'))</span></span><br><span class="line">model.add(keras.layers.Conv2D(</span><br><span class="line">    <span class="attr">filters=64,</span></span><br><span class="line">    <span class="attr">kernel_size=3,</span></span><br><span class="line">    <span class="attr">padding='same',</span></span><br><span class="line">    <span class="attr">activation='selu'))</span></span><br><span class="line">model.add(keras.layers.MaxPool2D(<span class="attr">pool_size=2))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 再来一遍，filters翻倍again</span></span><br><span class="line">model.add(keras.layers.Conv2D(</span><br><span class="line">    <span class="attr">filters=128,</span></span><br><span class="line">    <span class="attr">kernel_size=3,</span></span><br><span class="line">    <span class="attr">activation='selu',</span></span><br><span class="line">    <span class="attr">padding='same'))</span></span><br><span class="line">model.add(keras.layers.Conv2D(</span><br><span class="line">    <span class="attr">filters=128,</span></span><br><span class="line">    <span class="attr">kernel_size=3,</span></span><br><span class="line">    <span class="attr">padding='same',</span></span><br><span class="line">    <span class="attr">activation='selu'))</span></span><br><span class="line">model.add(keras.layers.MaxPool2D(<span class="attr">pool_size=2))</span></span><br><span class="line"></span><br><span class="line">model.add(keras.layers.Flatten()) <span class="comment"># 输出结果之前进行展平</span></span><br><span class="line">model.add(keras.layers.Dense(<span class="number">128</span>,<span class="attr">activation='relu'))</span></span><br><span class="line">model.add(keras.layers.Dense(<span class="number">10</span>,<span class="attr">activation='softmax'))</span></span><br><span class="line"></span><br><span class="line"><span class="attr">sgd=keras.optimizers.SGD(0.001)</span></span><br><span class="line">model.compile(</span><br><span class="line">    <span class="attr">loss="sparse_categorical_crossentropy",</span></span><br><span class="line">    <span class="attr">optimizer=sgd,</span></span><br><span class="line">    <span class="attr">metrics=["accuracy"])</span></span><br></pre></td></tr></table></figure></p>
<p>模型搭建完毕，查看模型细节。</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">model</span><span class="selector-class">.summary</span>()</span><br></pre></td></tr></table></figure>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">Model: "sequential"</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">conv2d (Conv2D)              (None, 28, 28, 32)        320       </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">max<span class="emphasis">_pooling2d_</span>1 (MaxPooling2 (None, 7, 7, 64)          0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv2d_4 (Conv2D)            (None, 7, 7, 128)         73856     </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">conv2d_5 (Conv2D)            (None, 7, 7, 128)         147584    </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">max<span class="emphasis">_pooling2d_</span>2 (MaxPooling2 (None, 3, 3, 128)         0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">flatten (Flatten)            (None, 1152)              0         </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense (Dense)                (None, 128)               147584    </span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br><span class="line">dense_1 (Dense)              (None, 10)                1290      </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 435,306</span><br><span class="line">Trainable params: 435,306</span><br><span class="line">Non-trainable params: 0</span><br><span class="line"><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span><span class="strong">_____</span></span><br></pre></td></tr></table></figure>
<p><b>设置停止训练的条件</b></p>
<p>如果在五轮训练中，loss没有降低，则停止模型训练。<br><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">callbacks</span>=[</span><br><span class="line">    keras.callbacks.EarlyStopping(patience=<span class="number">5</span>,min_delta=<span class="number">1</span>e-<span class="number">3</span>)]</span><br></pre></td></tr></table></figure></p>
<p><b>训练模型</b></p>
<p>这里定义一个history来保存模型训练的结果，以便后续matplotlib画图展示loss和acc的变化。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">history</span>=model.fit(</span><br><span class="line">    x_train_scaled,</span><br><span class="line">    y_train,</span><br><span class="line">    <span class="attribute">epochs</span>=10,</span><br><span class="line">    validation_data=(x_valid_scaled,y_valid),</span><br><span class="line">    <span class="attribute">callbacks</span>=callbacks)</span><br></pre></td></tr></table></figure></p>
<p><b>查看loss和acc变化的曲线</b></p>
<p>matplotlib是个好东西。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def plot_result(history):</span><br><span class="line">    <span class="attribute">data</span>=history.history</span><br><span class="line">    plt.plot(data[<span class="string">'accuracy'</span>],<span class="attribute">label</span>=<span class="string">'accuracy'</span>)</span><br><span class="line">    plt.plot(data[<span class="string">'loss'</span>],<span class="attribute">label</span>=<span class="string">'loss'</span>)</span><br><span class="line">    plt.plot(data[<span class="string">'val_accuracy'</span>],<span class="attribute">label</span>=<span class="string">'val_accuracy'</span>)</span><br><span class="line">    plt.plot(data[<span class="string">'val_loss'</span>],<span class="attribute">label</span>=<span class="string">'val_loss'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Epoch'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'value'</span>)</span><br><span class="line">    plt.ylim([0,1])</span><br><span class="line">    plt.legend(<span class="attribute">loc</span>=<span class="string">'lower left'</span>)</span><br><span class="line"></span><br><span class="line">plot_result(history)</span><br></pre></td></tr></table></figure></p>
<p>结果如下：<br><img src="https://s1.ax1x.com/2020/04/30/JLd1aD.png" alt></p>
<p><b>查看测试结果</b></p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss,<span class="attribute">accuracy</span>=model.evaluate(x_test_scaled,y_test)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'loss:'</span>,loss)</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'accuracy:'</span>,accuracy)</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/04/30/JLdWLV.png" alt></p>
<h3 id="CNN实现文本分类"><a href="#CNN实现文本分类" class="headerlink" title="CNN实现文本分类"></a>CNN实现文本分类</h3><p>对于文本预处理的过程在前面已经写过，其实都一样，区别只在于最后建模的部分。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"><span class="keyword">from</span> tensorflow import keras</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据集</span></span><br><span class="line"><span class="attribute">imdb</span>=keras.datasets.imdb</span><br><span class="line"></span><br><span class="line"><span class="attribute">vocab_size</span>=10000</span><br><span class="line"><span class="attribute">index_from</span>=3</span><br><span class="line"></span><br><span class="line">(x_train,y_train),(x_test,y_test)=imdb.load_data(</span><br><span class="line">    <span class="attribute">num_words</span>=vocab_size,index_from=index_from)</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(x_train.shape,y_train.shape)</span><br><span class="line"><span class="builtin-name">print</span>(x_test.shape,y_test.shape)</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(x_train[0])</span><br><span class="line"><span class="builtin-name">print</span>(y_train[0])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取词在词表中的词序</span></span><br><span class="line"><span class="attribute">word_index</span>=imdb.get_word_index()</span><br><span class="line"><span class="builtin-name">print</span>(word_index)</span><br><span class="line"><span class="builtin-name">print</span>()</span><br><span class="line"><span class="builtin-name">print</span>(len(word_index))</span><br><span class="line"></span><br><span class="line">word_index=&#123;k:(v+3) <span class="keyword">for</span> k,v <span class="keyword">in</span> word_index.items()&#125;</span><br><span class="line"></span><br><span class="line">word_index[<span class="string">'&lt;PAD&gt;'</span>]=0</span><br><span class="line">word_index[<span class="string">'&lt;START&gt;'</span>]=1</span><br><span class="line">word_index[<span class="string">'&lt;UNK&gt;'</span>]=2</span><br><span class="line">word_index[<span class="string">'&lt;END&gt;'</span>]=3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成反向词表</span></span><br><span class="line"><span class="attribute">reverse_word_index</span>=dict([(value,key) <span class="keyword">for</span> key,value <span class="keyword">in</span> word_index.items()])</span><br><span class="line"><span class="builtin-name">print</span>(reverse_word_index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练数据的原始文本信息</span></span><br><span class="line">def decode_review(text):</span><br><span class="line">    return <span class="string">' '</span>.join([reverse_word_index.<span class="builtin-name">get</span>(word_id,<span class="string">'&lt;UNK&gt;'</span>) <span class="keyword">for</span> word_id <span class="keyword">in</span> text])</span><br><span class="line"></span><br><span class="line">decode_review(x_train[0])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对数据进行预处理</span></span><br><span class="line"><span class="attribute">max_length</span>=300 # 500太长,这里只设置为300</span><br><span class="line"><span class="comment"># 处理训练集,保持所有句子的输入长度一致</span></span><br><span class="line"><span class="attribute">train_data</span>=keras.preprocessing.sequence.pad_sequences(</span><br><span class="line">    x_train,</span><br><span class="line">    <span class="attribute">value</span>=word_index[<span class="string">'&lt;PAD&gt;'</span>],</span><br><span class="line">    <span class="attribute">maxlen</span>=max_length,</span><br><span class="line">    <span class="attribute">padding</span>=<span class="string">'post'</span>)</span><br><span class="line">	</span><br><span class="line"><span class="comment"># 处理测试集</span></span><br><span class="line"><span class="attribute">test_data</span>=keras.preprocessing.sequence.pad_sequences(</span><br><span class="line">    x_test,</span><br><span class="line">    <span class="attribute">value</span>=word_index[<span class="string">'&lt;PAD&gt;'</span>],</span><br><span class="line">    <span class="attribute">maxlen</span>=max_length,</span><br><span class="line">    <span class="attribute">padding</span>=<span class="string">'post'</span>)</span><br><span class="line">	</span><br><span class="line"><span class="builtin-name">print</span>(train_data[0])</span><br><span class="line"><span class="builtin-name">print</span>(train_data.shape)</span><br><span class="line"><span class="builtin-name">print</span>(train_data[0].shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建CNN模型</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">embedding_dim</span>=16</span><br><span class="line"><span class="attribute">batch_size</span>=128</span><br><span class="line"></span><br><span class="line"><span class="attribute">model</span>=keras.models.Sequential([</span><br><span class="line">    keras.layers.Embedding(</span><br><span class="line">        vocab_size,</span><br><span class="line">        embedding_dim,</span><br><span class="line">        <span class="attribute">input_length</span>=max_length)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.Conv1D(</span><br><span class="line">    <span class="attribute">filters</span>=32,</span><br><span class="line">    # kernel_size:3 x 3</span><br><span class="line">    <span class="attribute">kernel_size</span>=3,</span><br><span class="line">    <span class="attribute">activation</span>=<span class="string">'relu'</span>,</span><br><span class="line">    <span class="attribute">padding</span>=<span class="string">'same'</span>,</span><br><span class="line">    input_shape=(300,16)))</span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.Conv1D(</span><br><span class="line">    <span class="attribute">filters</span>=32,</span><br><span class="line">    <span class="attribute">kernel_size</span>=3,</span><br><span class="line">    <span class="attribute">padding</span>=<span class="string">'same'</span>,</span><br><span class="line">    <span class="attribute">activation</span>=<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment"># 设置池化层</span></span><br><span class="line"><span class="comment"># pool_size:池化窗口大小</span></span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.MaxPool1D(<span class="attribute">pool_size</span>=2))</span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.Dropout(0.1))</span><br><span class="line"></span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.Conv1D(</span><br><span class="line">    <span class="attribute">filters</span>=64,</span><br><span class="line">    # kernel_size:3 x 3</span><br><span class="line">    <span class="attribute">kernel_size</span>=3,</span><br><span class="line">    <span class="attribute">activation</span>=<span class="string">'relu'</span>,</span><br><span class="line">    <span class="attribute">padding</span>=<span class="string">'same'</span>))</span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.Conv1D(</span><br><span class="line">    <span class="attribute">filters</span>=64,</span><br><span class="line">    <span class="attribute">kernel_size</span>=3,</span><br><span class="line">    <span class="attribute">padding</span>=<span class="string">'same'</span>,</span><br><span class="line">    <span class="attribute">activation</span>=<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment"># 设置池化层</span></span><br><span class="line"><span class="comment"># pool_size:池化窗口大小</span></span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.MaxPool1D(<span class="attribute">pool_size</span>=2))</span><br><span class="line"></span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.Flatten()) # 输出结果之前进行展平</span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.Dense(32,<span class="attribute">activation</span>=<span class="string">'relu'</span>))</span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.Dense(1,<span class="attribute">activation</span>=<span class="string">'sigmoid'</span>)) # 0/1</span><br><span class="line"></span><br><span class="line"><span class="attribute">sgd</span>=keras.optimizers.SGD(0.001)</span><br><span class="line">model.compile(</span><br><span class="line">    <span class="attribute">optimizer</span>=sgd,</span><br><span class="line">    <span class="attribute">loss</span>=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">	</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">epochs</span>=10</span><br><span class="line"></span><br><span class="line">callbacks=[</span><br><span class="line">    keras.callbacks.EarlyStopping(<span class="attribute">patience</span>=5,min_delta=1e-3)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="attribute">history</span>=model.fit(</span><br><span class="line">    train_data,</span><br><span class="line">    y_train,</span><br><span class="line">    <span class="attribute">epochs</span>=epochs,</span><br><span class="line">    <span class="attribute">batch_size</span>=batch_size,</span><br><span class="line">    <span class="attribute">validation_split</span>=0.2)</span><br><span class="line">	</span><br><span class="line">model.evaluate(test_data,y_test)</span><br></pre></td></tr></table></figure>
<p>这里分类的accuracy比较低，我估计原因是在词向量上，如果这里的词向量使用的是word2vec，结果可能会有很大的提高。</p>
<h2 id="循环神经网络实现"><a href="#循环神经网络实现" class="headerlink" title="循环神经网络实现"></a>循环神经网络实现</h2><p>RNN在NLP里面应用很广泛，这个部分主要是以NLP的相关任务作为示例。</p>
<h3 id="普通RNN实现"><a href="#普通RNN实现" class="headerlink" title="普通RNN实现"></a>普通RNN实现</h3><p>前面文本预处理的部分无区别，只在模型部分做修改，把之前的Con1D改成SimpleRNN。<br>代码如下：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"><span class="keyword">from</span> tensorflow import keras</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"><span class="attribute">imdb</span>=keras.datasets.imdb</span><br><span class="line"><span class="attribute">vocab_size</span>=10000</span><br><span class="line"><span class="attribute">index_from</span>=3</span><br><span class="line">(train_data,train_labels),(test_data,test_labels)=imdb.load_data(</span><br><span class="line">    <span class="attribute">num_words</span>=vocab_size,</span><br><span class="line">    <span class="attribute">index_from</span>=index_from)</span><br><span class="line">	</span><br><span class="line"><span class="builtin-name">print</span>(train_data.shape,train_labels.shape)</span><br><span class="line"><span class="builtin-name">print</span>(test_data.shape,test_labels.shape)</span><br><span class="line"><span class="builtin-name">print</span>(train_data[0],train_labels[0])</span><br><span class="line"></span><br><span class="line"><span class="attribute">word_index</span>=imdb.get_word_index()</span><br><span class="line"><span class="builtin-name">print</span>(word_index)</span><br><span class="line"></span><br><span class="line">word_index=&#123;k:(v+3) <span class="keyword">for</span> k,v <span class="keyword">in</span> word_index.items()&#125;</span><br><span class="line">word_index[<span class="string">'&lt;PAD&gt;'</span>]=0</span><br><span class="line">word_index[<span class="string">'&lt;START&gt;'</span>]=1</span><br><span class="line">word_index[<span class="string">'&lt;UNK&gt;'</span>]=2</span><br><span class="line">word_index[<span class="string">'&lt;END&gt;'</span>]=3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成反向词表</span></span><br><span class="line">reverse_word_index=&#123;v:k <span class="keyword">for</span> k,v <span class="keyword">in</span> word_index.items()&#125;</span><br><span class="line"><span class="builtin-name">print</span>(reverse_word_index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文本数据预处理</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">max_length</span>=300</span><br><span class="line"><span class="attribute">train_data</span>=keras.preprocessing.sequence.pad_sequences(</span><br><span class="line">    train_data,</span><br><span class="line">    <span class="attribute">value</span>=word_index[<span class="string">'&lt;PAD&gt;'</span>],</span><br><span class="line">    <span class="attribute">padding</span>=<span class="string">'post'</span>,</span><br><span class="line">    <span class="attribute">maxlen</span>=max_length)</span><br><span class="line"></span><br><span class="line"><span class="attribute">test_data</span>=keras.preprocessing.sequence.pad_sequences(</span><br><span class="line">    test_data,</span><br><span class="line">    <span class="attribute">value</span>=word_index[<span class="string">'&lt;PAD&gt;'</span>],</span><br><span class="line">    <span class="attribute">padding</span>=<span class="string">'post'</span>,</span><br><span class="line">    <span class="attribute">maxlen</span>=max_length)</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(train_data[0])</span><br><span class="line"><span class="builtin-name">print</span>(len(train_data[0]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单个单词映射为长度32的向量</span></span><br><span class="line"><span class="attribute">embedding_dim</span>=16</span><br><span class="line"><span class="attribute">batch_size</span>=128</span><br><span class="line"></span><br><span class="line"><span class="attribute">model</span>=keras.Sequential([</span><br><span class="line">    keras.layers.Embedding(</span><br><span class="line">        vocab_size,</span><br><span class="line">        embedding_dim,</span><br><span class="line">        <span class="attribute">input_length</span>=max_length),</span><br><span class="line">    keras.layers.SimpleRNN(</span><br><span class="line">        <span class="attribute">units</span>=64,</span><br><span class="line">        <span class="attribute">return_sequences</span>=<span class="literal">False</span>),</span><br><span class="line">    keras.layers.Dense(64,<span class="attribute">activation</span>=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(1,<span class="attribute">activation</span>=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line">model.compile(</span><br><span class="line">    <span class="attribute">optimizer</span>=<span class="string">'adam'</span>,</span><br><span class="line">    <span class="attribute">loss</span>=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">	</span><br><span class="line">model.fit(</span><br><span class="line">    train_data,</span><br><span class="line">    train_labels,</span><br><span class="line">    <span class="attribute">epochs</span>=30,</span><br><span class="line">    <span class="attribute">batch_size</span>=batch_size,</span><br><span class="line">    <span class="attribute">validation_split</span>=0.2)</span><br><span class="line">	</span><br><span class="line">model.evaluate(test_data,test_labels,<span class="attribute">batch_size</span>=batch_size)</span><br></pre></td></tr></table></figure></p>
<h3 id="Padding-Pooling"><a href="#Padding-Pooling" class="headerlink" title="Padding_Pooling"></a>Padding_Pooling</h3><p>这个东西分类的精确度比RNN高多了，震惊ing。<br>数据预处理的部分都是一样的，这里就只放模型块了：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">embedding_dim</span>=16</span><br><span class="line"><span class="attribute">batch_size</span>=128</span><br><span class="line"></span><br><span class="line"><span class="attribute">model</span>=keras.models.Sequential([</span><br><span class="line">    keras.layers.Embedding(</span><br><span class="line">        vocab_size,</span><br><span class="line">        embedding_dim,</span><br><span class="line">        <span class="attribute">input_length</span>=max_length),</span><br><span class="line">    keras.layers.GlobalAveragePooling1D(),</span><br><span class="line">    keras.layers.Dense(64,<span class="attribute">activation</span>=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(1,<span class="attribute">activation</span>=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line">model.summary()</span><br><span class="line">model.compile(</span><br><span class="line">    <span class="attribute">optimizer</span>=<span class="string">'adam'</span>,</span><br><span class="line">    <span class="attribute">loss</span>=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure></p>
<p>分类准确率高达：0.85.</p>
<h3 id="双向RNN"><a href="#双向RNN" class="headerlink" title="双向RNN"></a>双向RNN</h3><p>区别仍然只在模型部分，双向RNN可以设置多层：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Bidirectional(</span><br><span class="line">        keras.layers.SimpleRNN(</span><br><span class="line">            <span class="attribute">units</span>=64,</span><br><span class="line">            <span class="attribute">return_sequences</span>=<span class="literal">False</span>)),</span><br></pre></td></tr></table></figure></p>
<p>这个值多复制几次,前面的return_sequences设置为True,最后一层设置为False即可，不过层数太多训练会很慢。</p>
<p>数据部分略过，只放模型:<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建模型</span></span><br><span class="line"> <span class="attribute">embedding_dim</span>=16</span><br><span class="line"> <span class="attribute">batch_size</span>=128</span><br><span class="line"></span><br><span class="line"> <span class="attribute">model</span>=keras.models.Sequential([</span><br><span class="line">     keras.layers.Embedding(</span><br><span class="line">         vocab_size,</span><br><span class="line">         embedding_dim,</span><br><span class="line">         <span class="attribute">input_length</span>=max_length),</span><br><span class="line">    keras.layers.Bidirectional(</span><br><span class="line">        keras.layers.SimpleRNN(</span><br><span class="line">            <span class="attribute">units</span>=64,</span><br><span class="line">            <span class="attribute">return_sequences</span>=<span class="literal">False</span>)),</span><br><span class="line">    keras.layers.Dense(64,<span class="attribute">activation</span>=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(1,<span class="attribute">activation</span>=<span class="string">'sigmoid'</span>)</span><br><span class="line"> ])</span><br><span class="line"></span><br><span class="line"> model.summary()</span><br><span class="line"> model.compile(</span><br><span class="line">     <span class="attribute">optimizer</span>=<span class="string">'adam'</span>,</span><br><span class="line">     <span class="attribute">loss</span>=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">     metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure></p>
<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>这个部分只需要在RNN的基础上把SimpleRNN改成LSTM，再对参数进行设置即可。<br>主要改动参数有两个，Embedding层的batch_input_shpe，LSTM层的stateful和recurrent_initializer。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 单个单词映射为长度32的向量</span></span><br><span class="line"><span class="attribute">embedding_dim</span>=16</span><br><span class="line"><span class="attribute">batch_size</span>=25</span><br><span class="line"></span><br><span class="line"><span class="attribute">model</span>=keras.Sequential([</span><br><span class="line">    keras.layers.Embedding(</span><br><span class="line">        vocab_size,</span><br><span class="line">        embedding_dim,</span><br><span class="line">        batch_input_shape=[batch_size,None]),</span><br><span class="line">    keras.layers.LSTM(</span><br><span class="line">        <span class="attribute">units</span>=64,</span><br><span class="line">        <span class="attribute">stateful</span>=<span class="literal">True</span>,</span><br><span class="line">        <span class="attribute">recurrent_initializer</span>=<span class="string">'orthogonal'</span>,</span><br><span class="line">        <span class="attribute">return_sequences</span>=<span class="literal">True</span>),</span><br><span class="line">    keras.layers.Dense(vocab_size,<span class="attribute">activation</span>=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(1,<span class="attribute">activation</span>=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line">model.compile(</span><br><span class="line">    <span class="attribute">optimizer</span>=<span class="string">'adam'</span>,</span><br><span class="line">    <span class="attribute">loss</span>=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure></p>
<h2 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h2><p>这个部分主要使用到两个功能 callbacks 和 load_weights。</p>
<p>首先这里先给出一个完整的神经网络模型，主要工作是对图片进行分类。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"><span class="keyword">from</span> tensorflow import keras</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing import StandardScaler</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">fashion_mnist = keras.datasets.fashion_mnist</span><br><span class="line">(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()</span><br><span class="line">x_valid, x_train = x_train_all[:5000], x_train_all[5000:]</span><br><span class="line">y_valid, y_train = y_train_all[:5000], y_train_all[5000:]</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(x_valid.shape, y_valid.shape)</span><br><span class="line"><span class="builtin-name">print</span>(x_train.shape, y_train.shape)</span><br><span class="line"><span class="builtin-name">print</span>(x_test.shape, y_test.shape)</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(np.max(x_train),np.min(x_train))</span><br><span class="line"></span><br><span class="line"><span class="attribute">scaler</span>=StandardScaler()</span><br><span class="line"></span><br><span class="line"><span class="attribute">x_train_scaled</span>=scaler.fit_transform(</span><br><span class="line">    x_train.astype(np.float32).reshape(-1,1)).reshape(-1,28,28)</span><br><span class="line"><span class="attribute">x_valid_scaled</span>=scaler.transform(</span><br><span class="line">    x_valid.astype(np.float32).reshape(-1,1)).reshape(-1,28,28)</span><br><span class="line"><span class="attribute">x_test_scaled</span>=scaler.transform(</span><br><span class="line">    x_test.astype(np.float32).reshape(-1,1)).reshape(-1,28,28)</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(np.max(x_train_scaled),np.min(x_train_scaled))</span><br><span class="line"></span><br><span class="line"><span class="attribute">model</span>=keras.models.Sequential()</span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.Flatten(input_shape=[28,28]))</span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.Dense(300,<span class="attribute">activation</span>=<span class="string">"relu"</span>))</span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.Dense(100,<span class="attribute">activation</span>=<span class="string">"relu"</span>))</span><br><span class="line">model.<span class="builtin-name">add</span>(keras.layers.Dense(10,<span class="attribute">activation</span>=<span class="string">"softmax"</span>))</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    <span class="attribute">loss</span>=<span class="string">"sparse_categorical_crossentropy"</span>,</span><br><span class="line">    <span class="attribute">optimizer</span>=<span class="string">"sgd"</span>,</span><br><span class="line">    metrics=[<span class="string">"accuracy"</span>])</span><br></pre></td></tr></table></figure></p>
<p>模型已经构建完成，下面一步就是训练，我们需要做的就是，保存训练过程中的参数，或是训练过多少轮的数据。</p>
<p>设置保存模型的文件夹:<br><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">logdir=<span class="built_in">os</span>.<span class="built_in">path</span>.join(<span class="string">'graph_def_and_weights'</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">os</span>.<span class="built_in">path</span>.exists(logdir):</span><br><span class="line">    <span class="built_in">os</span>.mkdir(logdir)</span><br><span class="line">output_model_file=<span class="built_in">os</span>.<span class="built_in">path</span>.join(logdir,<span class="string">'fashion_mnist_weights.h5'</span>)</span><br></pre></td></tr></table></figure></p>
<p>设置一个callbacks，其中需要编写需要保存的信息以及训练停止的条件：<br><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">'''</span><br><span class="line">patience:如果训练过程中,经过设定值的epoch数后没有改进,训练停止</span><br><span class="line">min<span class="emphasis">_delat:监视数量的最小变化,即最小变化小于min_</span>delta，将不视为改进</span><br><span class="line">'''</span><br><span class="line">'''</span><br><span class="line">save<span class="emphasis">_best_</span>only: True:只保留最好的模型 False:反</span><br><span class="line">save<span class="emphasis">_weights_</span>only:True:只保存参数; False:同时保存模型和参数;</span><br><span class="line">'''</span><br><span class="line">callbacks=[</span><br><span class="line"><span class="code">    keras.callbacks.TensorBoard(logdir),</span></span><br><span class="line"><span class="code">    keras.callbacks.ModelCheckpoint(</span></span><br><span class="line"><span class="code">        output_model_file,</span></span><br><span class="line"><span class="code">        save_best_only=True,</span></span><br><span class="line"><span class="code">        save_weights_only=True),</span></span><br><span class="line"><span class="code">    keras.callbacks.EarlyStopping(patience=5,min_delta=1e-3)</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure></p>
<p>将callbacks放入训练中：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">history</span>=model.fit(</span><br><span class="line">    x_train_scaled,</span><br><span class="line">    y_train,<span class="attribute">epochs</span>=10,</span><br><span class="line">    validation_data=(x_valid_scaled,y_valid),</span><br><span class="line">    <span class="attribute">callbacks</span>=callbacks)</span><br></pre></td></tr></table></figure></p>
<p>通过pandas查看loss和acc在训练中的变化曲线：<br><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">def</span> <span class="selector-tag">plot_learning_curves</span>(history):</span><br><span class="line">    <span class="selector-tag">pd</span><span class="selector-class">.DataFrame</span>(history.history)<span class="selector-class">.plot</span>(figsize=(<span class="number">8</span>, <span class="number">5</span>))</span><br><span class="line">    <span class="selector-tag">plt</span><span class="selector-class">.grid</span>(True)</span><br><span class="line">    <span class="selector-tag">plt</span><span class="selector-class">.gca</span>()<span class="selector-class">.set_ylim</span>(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="selector-tag">plt</span><span class="selector-class">.show</span>()</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">plot_learning_curves</span>(history)</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/05/04/YCXkXq.png" alt></p>
<p>验证数据:<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="name">model</span>.evaluate(<span class="name">x_test_scaled</span>,y_test))</span><br></pre></td></tr></table></figure></p>
<p>至此可以看到已经有保存好的模型，再重新编写一个网络模型，model.compile之后不执行训练，直接调用model.load_weights。再调用测试集。<br>结果是一样的：<br><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">output_file=os.path.join(logdir,<span class="string">'fashion_mnist.model.h5'</span>)</span><br><span class="line"><span class="keyword">model</span>.load_weights(output_file)</span><br><span class="line"><span class="keyword">model</span>.evaluate(x_test_scaled,y_test)</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/04/26/TensorFlow-2-0-使用指南/" data-id="ckymbgwq2001w0gukuee5orzw" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/05/18/Django在开发中的基本操作小结/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Django在开发中的基本操作小结
        
      </div>
    </a>
  
  
    <a href="/2020/04/14/【统计自然语言处理】形式语言与自动机/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">【统计自然语言处理】形式语言与自动机</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
    <h3 class="widget-title">联系方式</h3>
    <div class="widget">
	  <li><a>klausvon@163.com</a></li>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">目录</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CTF/">CTF</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/HTML/">HTML</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP-知识图谱/">NLP,知识图谱</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/VQA/">VQA</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/XSS漏洞学习/">XSS漏洞学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/代码审计/">代码审计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/开发/">开发</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学学习/">数学学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/漏洞学习/">漏洞学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境配置/">环境配置</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/神经网络/">神经网络</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CTF-Web/">CTF_Web</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HTML/">HTML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JavaScript/">JavaScript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ML/">ML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Model-Compression/">Model Compression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PHP/">PHP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQL-injection/">SQL_injection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VQA/">VQA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/XXE/">XXE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/凸包算法/">凸包算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/开发/">开发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数学学习/">数学学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据挖掘/">数据挖掘</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/环境配置/">环境配置</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/知识图谱/">知识图谱</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/神经网络/">神经网络</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithm/" style="font-size: 15px;">Algorithm</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/CTF-Web/" style="font-size: 18.33px;">CTF_Web</a> <a href="/tags/HTML/" style="font-size: 10px;">HTML</a> <a href="/tags/JavaScript/" style="font-size: 10px;">JavaScript</a> <a href="/tags/ML/" style="font-size: 11.67px;">ML</a> <a href="/tags/Model-Compression/" style="font-size: 10px;">Model Compression</a> <a href="/tags/NLP/" style="font-size: 20px;">NLP</a> <a href="/tags/PHP/" style="font-size: 10px;">PHP</a> <a href="/tags/Python/" style="font-size: 11.67px;">Python</a> <a href="/tags/SQL-injection/" style="font-size: 13.33px;">SQL_injection</a> <a href="/tags/VQA/" style="font-size: 10px;">VQA</a> <a href="/tags/XXE/" style="font-size: 10px;">XXE</a> <a href="/tags/凸包算法/" style="font-size: 10px;">凸包算法</a> <a href="/tags/大数据/" style="font-size: 10px;">大数据</a> <a href="/tags/开发/" style="font-size: 18.33px;">开发</a> <a href="/tags/数学学习/" style="font-size: 11.67px;">数学学习</a> <a href="/tags/数据挖掘/" style="font-size: 11.67px;">数据挖掘</a> <a href="/tags/环境配置/" style="font-size: 10px;">环境配置</a> <a href="/tags/知识图谱/" style="font-size: 16.67px;">知识图谱</a> <a href="/tags/神经网络/" style="font-size: 15px;">神经网络</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/01/12/单调栈的奇妙冒险/">单调栈的奇妙冒险</a>
          </li>
        
          <li>
            <a href="/2021/06/03/Basic-Understanding-of-Optimization/">Basic Understanding of Optimization</a>
          </li>
        
          <li>
            <a href="/2021/06/02/Why-Deep-Structure/">Why Deep Structure</a>
          </li>
        
          <li>
            <a href="/2021/05/23/Model-Compression-基本概念/">What is Model Compression</a>
          </li>
        
          <li>
            <a href="/2020/05/21/CSS在开发中的基本操作小结/">CSS在开发中的基本操作小结</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    <div class="widget-wrap">
    <h3 class="widget-title">友情链接</h3>
    <div class="widget">
	 <a class="theme-link"  href="https://mteacher.top/"> martini's blog </a><span>&nbsp;&nbsp;</span>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 Klaus<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>